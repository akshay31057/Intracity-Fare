{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "# Importing some visualization libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "# importing alll the necessary packages to use the various classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "from sklearn.cross_validation import train_test_split #to split the dataset for training and testing\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "from sklearn.ensemble import RandomForestClassifier # A combine model of many decision trees\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "def frange(start, stop, step):\n",
    "     i = start\n",
    "     while i < stop:\n",
    "         yield i\n",
    "         i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris=pd.read_csv('intracity_fare_train.csv')\n",
    "list(iris)\n",
    "#iris=iris.assign(prod=iris['DISTANCE']*iris['TRAFFIC_STUCK_TIME'])\n",
    "df= pd.DataFrame(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "import numpy as np\n",
    "from numpy import arcsin,sin ,arctan2,cos\n",
    "tc = pi/2;\n",
    "R = 6371\n",
    "def latlon(lat1, lon1, d):\n",
    "    lat1 *= pi/180\n",
    "    lon1 *= pi/180\n",
    "    lat =arcsin(sin(lat1)*np.cos(d/R)+cos(lat1)*sin(d)*cos(tc))\n",
    "    dlon=arctan2(sin(tc)*sin(d/R)*cos(lat1),cos(d)-sin(lat1)*sin(lat))\n",
    "    lon=np.mod( lon1-dlon+pi,2*pi )-pi\n",
    "    lat *= 180/pi\n",
    "    lon *= 180/pi\n",
    "    lon[lon < 0] = 180 - np.abs(lon[lon < 0])\n",
    "    lat[lat < 0] = 180 - np.abs(lat[lat < 0])\n",
    "    return lat,lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['STARTING_LATITUDE', 'DESTINATION_LATITUDE'], how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing missing destination coordinates\n",
    "#print(df.shape)\n",
    "\n",
    "#print(df.shape)\n",
    "df[['STARTING_LATITUDE','DESTINATION_LATITUDE']] = df[['STARTING_LATITUDE','DESTINATION_LATITUDE']].fillna(value=0)\n",
    "\n",
    "temp = df['DESTINATION_LATITUDE']==0\n",
    "# print(interfare[temp])\n",
    "df.loc[temp,'DESTINATION_LATITUDE'],df.loc[temp, 'DESTINATION_LONGITUDE'] = latlon(df.loc[temp,'STARTING_LATITUDE'], df.loc[temp,'STARTING_LONGITUDE'], df.loc[temp,'DISTANCE']/2)\n",
    "temp = df['STARTING_LATITUDE']==0\n",
    "df.loc[temp,'STARTING_LATITUDE'],df.loc[temp, 'STARTING_LONGITUDE'] = latlon(df.loc[temp,'DESTINATION_LATITUDE'], df.loc[temp,'DESTINATION_LONGITUDE'], df.loc[temp,'DISTANCE']/2)\n",
    "#df\n",
    "# print(interfare[temp])\n",
    "#df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[\n",
    " 'STARTING_LATITUDE',\n",
    " 'STARTING_LONGITUDE',\n",
    " 'DESTINATION_LATITUDE',\n",
    " 'DESTINATION_LONGITUDE',\n",
    " 'VEHICLE_TYPE',\n",
    " 'TOTAL_LUGGAGE_WEIGHT',\n",
    " 'WAIT_TIME',\n",
    " 'TRAFFIC_STUCK_TIME',\n",
    " 'DISTANCE',\n",
    " 'FARE'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df['VEHICLE_TYPE']=df['VEHICLE_TYPE'].apply(lambda x: x.upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['TOTAL_LUGGAGE_WEIGHT']=df['TOTAL_LUGGAGE_WEIGHT'].fillna(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                           0\n",
       "TIMESTAMP                    0\n",
       "STARTING_LATITUDE            0\n",
       "STARTING_LONGITUDE           0\n",
       "DESTINATION_LATITUDE         0\n",
       "DESTINATION_LONGITUDE        0\n",
       "VEHICLE_TYPE                 0\n",
       "TOTAL_LUGGAGE_WEIGHT         0\n",
       "WAIT_TIME                14095\n",
       "TRAFFIC_STUCK_TIME           0\n",
       "DISTANCE                     0\n",
       "FARE                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['WAIT_TIME']=df['WAIT_TIME'].fillna(15.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_map = {'AC BUS':3,\n",
    " 'AUTO RICKSHAW':4,\n",
    " 'BUS':1,\n",
    " 'METRO':2,\n",
    " 'MINI BUS':0,\n",
    " 'TAXI AC':6,\n",
    " 'TAXI NON AC':5}\n",
    "\n",
    "df['VEHICLE_TYPE']=df['VEHICLE_TYPE'].apply(lambda x: target_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing alll the necessary packages to use the various classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "from sklearn.cross_validation import train_test_split #to split the dataset for training and testing\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "from sklearn.ensemble import RandomForestClassifier # A combine model of many decision trees\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13763, 12)\n",
      "(5899, 12)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size = 0.3, random_state=1212)# in this our main data is split into train and test\n",
    "# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'TIMESTAMP',\n",
       " 'STARTING_LATITUDE',\n",
       " 'STARTING_LONGITUDE',\n",
       " 'DESTINATION_LATITUDE',\n",
       " 'DESTINATION_LONGITUDE',\n",
       " 'VEHICLE_TYPE',\n",
       " 'TOTAL_LUGGAGE_WEIGHT',\n",
       " 'WAIT_TIME',\n",
       " 'TRAFFIC_STUCK_TIME',\n",
       " 'DISTANCE',\n",
       " 'FARE']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train[['STARTING_LATITUDE',\n",
    " 'STARTING_LONGITUDE',\n",
    " 'DESTINATION_LATITUDE',\n",
    " 'DESTINATION_LONGITUDE',\n",
    " 'VEHICLE_TYPE',\n",
    " 'TOTAL_LUGGAGE_WEIGHT',\n",
    " 'WAIT_TIME',\n",
    " 'TRAFFIC_STUCK_TIME',\n",
    " 'DISTANCE']]# taking the training data features\n",
    "\n",
    "train_y = train[['FARE']]# output of our training data\n",
    "test_X = test[['STARTING_LATITUDE',\n",
    " 'STARTING_LONGITUDE',\n",
    " 'DESTINATION_LATITUDE',\n",
    " 'DESTINATION_LONGITUDE',\n",
    " 'VEHICLE_TYPE',\n",
    " 'TOTAL_LUGGAGE_WEIGHT',\n",
    " 'WAIT_TIME',\n",
    " 'TRAFFIC_STUCK_TIME',\n",
    " 'DISTANCE']]# taking the training data features\n",
    "# taking test data features\n",
    "test_y = test[['FARE']]   #output value of test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression is 1 0.140512339985 -0.192876937883\n",
      "The accuracy of the Logistic Regression is 2 0.43656029487 0.239435885192\n",
      "The accuracy of the Logistic Regression is 3 0.611845138662 0.439199533939\n",
      "The accuracy of the Logistic Regression is 4 0.689581323851 -0.225884559721\n",
      "The accuracy of the Logistic Regression is 5 0.716140867612 -0.52715051817\n",
      "The accuracy of the Logistic Regression is 6 0.727238827711 -12.1117036448\n",
      "The accuracy of the Logistic Regression is 7 0.738639398329 -2.45296643064\n",
      "The accuracy of the Logistic Regression is 8 0.730559309587 -0.769013507319\n",
      "The accuracy of the Logistic Regression is 9 0.705665124275 0.150343344091\n",
      "The accuracy of the Logistic Regression is 10 0.680995824853 0.578651860777\n",
      "The accuracy of the Logistic Regression is 11 0.674593350453 0.726144300512\n",
      "The accuracy of the Logistic Regression is 12 0.671586702823 0.761409191015\n",
      "The accuracy of the Logistic Regression is 13 0.65950576374 0.765283659375\n",
      "The accuracy of the Logistic Regression is 14 0.655792845789 0.767311584899\n",
      "The accuracy of the Logistic Regression is 15 0.63281858289 0.767994310682\n",
      "The accuracy of the Logistic Regression is 16 0.626331400617 0.768294042084\n",
      "The accuracy of the Logistic Regression is 17 0.625533441201 0.767500173617\n"
     ]
    }
   ],
   "source": [
    "#model = LogisticRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for i in range(1,18):\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=i)\n",
    "\n",
    "    regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=i),\n",
    "                              n_estimators=250, random_state=rng)\n",
    "\n",
    "    #len(prediction)\n",
    "    regr_1.fit(train_X, train_y)\n",
    "    regr_2.fit(train_X, train_y)\n",
    "    y_1 = regr_1.predict(test_X)\n",
    "    y_2 = regr_2.predict(test_X)\n",
    "    len(test_y)\n",
    "    print('The accuracy of the Logistic Regression is',i,r2_score(y_1,test_y),r2_score(y_2,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression is 17 0.741636625316 0.767994310682\n"
     ]
    }
   ],
   "source": [
    "    regr_1 = DecisionTreeRegressor(max_depth=7)\n",
    "\n",
    "    regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=15),\n",
    "                              n_estimators=250, random_state=1024)\n",
    "\n",
    "    #len(prediction)\n",
    "    regr_1.fit(train_X, train_y)\n",
    "    regr_2.fit(train_X, train_y)\n",
    "    y_1 = regr_1.predict(test_X)\n",
    "    y_2 = regr_2.predict(test_X)\n",
    "    len(test_y)\n",
    "    print('The accuracy of the Logistic Regression is',i,r2_score(y_1,test_y),r2_score(y_2,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression is 1 0.18814939713 -0.238767094674\n",
      "The accuracy of the Logistic Regression is 2 0.497460973123 0.255808110724\n",
      "The accuracy of the Logistic Regression is 3 0.662319727056 0.335555030238\n",
      "The accuracy of the Logistic Regression is 4 0.737971333324 -0.155454855641\n",
      "The accuracy of the Logistic Regression is 5 0.762356324145 -0.994448183098\n",
      "The accuracy of the Logistic Regression is 6 0.774025864254 -0.92482425306\n",
      "The accuracy of the Logistic Regression is 7 0.771120183893 -8.44201081478\n",
      "The accuracy of the Logistic Regression is 8 0.770810329587 -0.803718918928\n",
      "The accuracy of the Logistic Regression is 9 0.743930804318 0.162372564292\n",
      "The accuracy of the Logistic Regression is 10 0.717891498784 0.652922147004\n",
      "The accuracy of the Logistic Regression is 11 0.714138352464 0.774613483633\n",
      "The accuracy of the Logistic Regression is 12 0.664389089639 0.806901319676\n",
      "The accuracy of the Logistic Regression is 13 0.642554434894 0.816819904243\n",
      "The accuracy of the Logistic Regression is 14 0.637218474669 0.818500537068\n",
      "The accuracy of the Logistic Regression is 15 0.621476511068 0.821342105225\n",
      "The accuracy of the Logistic Regression is 16 0.604566135365 0.820340842201\n",
      "The accuracy of the Logistic Regression is 17 0.620105395162 0.820496090777\n"
     ]
    }
   ],
   "source": [
    "#model = LogisticRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for i in range(1,18):\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=i)\n",
    "\n",
    "    regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=i),\n",
    "                              n_estimators=250, random_state=1024)\n",
    "\n",
    "    #len(prediction)\n",
    "    regr_1.fit(train_X, train_y)\n",
    "    regr_2.fit(train_X, train_y)\n",
    "    y_1 = regr_1.predict(test_X)\n",
    "    y_2 = regr_2.predict(test_X)\n",
    "    len(test_y)\n",
    "    print('The accuracy of the Logistic Regression is',i,r2_score(y_1,test_y),r2_score(y_2,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression is 200 0.77120599529 0.821213632315\n",
      "The accuracy of the Logistic Regression is 250 0.784759959552 0.821342105225\n",
      "The accuracy of the Logistic Regression is 300 0.777895978872 0.821153740044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr_1 = DecisionTreeRegressor(max_depth=7)\n",
    "for k in range(200,350,50):\n",
    "    regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=15),\n",
    "                                  n_estimators=k, random_state=rng)\n",
    "\n",
    "        #len(prediction)\n",
    "    regr_1.fit(train_X, train_y)\n",
    "    regr_2.fit(train_X, train_y)\n",
    "    y_1 = regr_1.predict(test_X)\n",
    "    y_2 = regr_2.predict(test_X)\n",
    "    len(test_y)\n",
    "    print('The accuracy of the Logistic Regression is',k,r2_score(y_1,test_y),r2_score(y_2,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19662"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression is 18 0.612871618232 0.763280397038\n",
      "The accuracy of the Logistic Regression is 19 0.616472133007 0.764141763268\n",
      "The accuracy of the Logistic Regression is 20 0.635705387981 0.760910152298\n",
      "The accuracy of the Logistic Regression is 21 0.624838799055 0.762550138527\n",
      "The accuracy of the Logistic Regression is 22 0.634886728437 0.762434739814\n",
      "The accuracy of the Logistic Regression is 23 0.623199517327 0.763671863067\n",
      "The accuracy of the Logistic Regression is 24 0.621552162408 0.760748776271\n",
      "The accuracy of the Logistic Regression is 25 0.651530395608 0.761436566202\n",
      "The accuracy of the Logistic Regression is 26 0.629993441354 0.762211357694\n",
      "The accuracy of the Logistic Regression is 27 0.624719981823 0.763174382758\n",
      "The accuracy of the Logistic Regression is 28 0.63551482449 0.760362932821\n",
      "The accuracy of the Logistic Regression is 29 0.639883349453 0.760490638846\n",
      "The accuracy of the Logistic Regression is 30 0.644926957721 0.763159289639\n",
      "The accuracy of the Logistic Regression is 31 0.629047643149 0.76125608353\n",
      "The accuracy of the Logistic Regression is 32 0.632888981639 0.762119685607\n",
      "The accuracy of the Logistic Regression is 33 0.624925632246 0.759832359053\n",
      "The accuracy of the Logistic Regression is 34 0.63525703451 0.761673859963\n",
      "The accuracy of the Logistic Regression is 35 0.628512912121 0.762649777133\n",
      "The accuracy of the Logistic Regression is 36 0.62321357866 0.759833886403\n",
      "The accuracy of the Logistic Regression is 37 0.615959103451 0.76176809097\n",
      "The accuracy of the Logistic Regression is 38 0.631601447911 0.76176809097\n",
      "The accuracy of the Logistic Regression is 39 0.632508942762 0.76176809097\n",
      "The accuracy of the Logistic Regression is 40 0.620319483993 0.76176809097\n"
     ]
    }
   ],
   "source": [
    "#model = LogisticRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "rng = 1024\n",
    "for i in range(18,41):\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=i)\n",
    "\n",
    "    regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=i),\n",
    "                              n_estimators=250, random_state=rng)\n",
    "\n",
    "    #len(prediction)\n",
    "    regr_1.fit(train_X, train_y)\n",
    "    regr_2.fit(train_X, train_y)\n",
    "    y_1 = regr_1.predict(test_X)\n",
    "    y_2 = regr_2.predict(test_X)\n",
    "    len(test_y)\n",
    "    print('The accuracy of the Logistic Regression is',i,r2_score(y_1,test_y),r2_score(y_2,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "\n",
    "tr=df\n",
    "tE=pd.read_csv('intracity_fare_test.csv')\n",
    "te=pd.DataFrame(tE)\n",
    "\n",
    "model=linear_model.LogisticRegression()\n",
    "tr_X = tr[['STARTING_LATITUDE',\n",
    " 'STARTING_LONGITUDE',\n",
    " 'DESTINATION_LATITUDE',\n",
    " 'DESTINATION_LONGITUDE',\n",
    " 'VEHICLE_TYPE',\n",
    " 'TOTAL_LUGGAGE_WEIGHT',\n",
    " 'WAIT_TIME',\n",
    " 'TRAFFIC_STUCK_TIME',\n",
    " 'DISTANCE']]# taking the training data features\n",
    "\n",
    "tr_y = tr[['FARE']]# output of our training data\n",
    "#######\n",
    "te.dropna(subset=['STARTING_LATITUDE', 'DESTINATION_LATITUDE'], how='all',inplace=True)\n",
    "#print(df.shape)\n",
    "te[['STARTING_LATITUDE','DESTINATION_LATITUDE']] = te[['STARTING_LATITUDE','DESTINATION_LATITUDE']].fillna(value=0)\n",
    "\n",
    "temp = te['DESTINATION_LATITUDE']==0\n",
    "# print(interfare[temp])\n",
    "te.loc[temp,'DESTINATION_LATITUDE'],te.loc[temp, 'DESTINATION_LONGITUDE'] = latlon(te.loc[temp,'STARTING_LATITUDE'], te.loc[temp,'STARTING_LONGITUDE'], te.loc[temp,'DISTANCE']/2)\n",
    "temp = te['STARTING_LATITUDE']==0\n",
    "te.loc[temp,'STARTING_LATITUDE'],te.loc[temp, 'STARTING_LONGITUDE'] = latlon(te.loc[temp,'DESTINATION_LATITUDE'], te.loc[temp,'DESTINATION_LONGITUDE'], te.loc[temp,'DISTANCE']/2)\n",
    "\n",
    "te['VEHICLE_TYPE']=te['VEHICLE_TYPE'].apply(lambda x: x.upper())\n",
    "te['TOTAL_LUGGAGE_WEIGHT']=te['TOTAL_LUGGAGE_WEIGHT'].fillna(7)\n",
    "te['WAIT_TIME']=te['WAIT_TIME'].fillna(0)\n",
    "target_map = {'AC BUS':3,\n",
    " 'AUTO RICKSHAW':4,\n",
    " 'BUS':1,\n",
    " 'METRO':2,\n",
    " 'MINI BUS':0,\n",
    " 'TAXI AC':6,\n",
    " 'TAXI NON AC':5}\n",
    "\n",
    "te['VEHICLE_TYPE']=te['VEHICLE_TYPE'].apply(lambda x: target_map[x])\n",
    "te=te.dropna()\n",
    "te_X = te[['STARTING_LATITUDE',\n",
    " 'STARTING_LONGITUDE',\n",
    " 'DESTINATION_LATITUDE',\n",
    " 'DESTINATION_LONGITUDE',\n",
    " 'VEHICLE_TYPE',\n",
    " 'TOTAL_LUGGAGE_WEIGHT',\n",
    " 'WAIT_TIME',\n",
    " 'TRAFFIC_STUCK_TIME',\n",
    " 'DISTANCE']]# taking the training data features\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "regr_1 = DecisionTreeRegressor(max_depth=7)\n",
    "\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=15),\n",
    "                              n_estimators=250, random_state=1024)\n",
    "\n",
    "    #len(prediction)\n",
    "regr_1.fit(tr_X, tr_y)\n",
    "regr_2.fit(tr_X, tr_y)\n",
    "y_1 = regr_1.predict(te_X)\n",
    "y_2 = regr_2.predict(te_X)\n",
    "pred=pd.DataFrame(y_2)\n",
    "pred.index=pred.index+1\n",
    "# do for 12 and 13\n",
    "pred.to_csv(path_or_buf='answer4_checkf1.csv',header=['FARE'],mode='w',index_label='ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 12 0.716063557883\n",
      "4 4 12 0.724995538778\n",
      "5 4 12 0.72814531547\n",
      "6 4 12 0.732655327388\n",
      "7 4 12 0.733657556998\n",
      "8 4 12 0.736731196214\n",
      "9 4 12 0.73837702971\n",
      "10 4 12 0.739981065581\n",
      "11 4 12 0.738863826522\n",
      "12 4 12 0.740111174796\n",
      "13 4 12 0.739939945276\n",
      "14 4 12 0.741443207133\n",
      "15 4 12 0.740993856877\n",
      "3 4 12.5 0.716063557883\n",
      "4 4 12.5 0.724995538778\n",
      "5 4 12.5 0.72814531547\n",
      "6 4 12.5 0.732655327388\n",
      "7 4 12.5 0.733657556998\n",
      "8 4 12.5 0.736731196214\n",
      "9 4 12.5 0.73837702971\n",
      "10 4 12.5 0.739981065581\n",
      "11 4 12.5 0.738863826522\n",
      "12 4 12.5 0.740111174796\n",
      "13 4 12.5 0.739939945276\n",
      "14 4 12.5 0.741443207133\n",
      "15 4 12.5 0.740993856877\n",
      "3 4 13.0 0.716063557883\n",
      "4 4 13.0 0.724995538778\n",
      "5 4 13.0 0.72814531547\n",
      "6 4 13.0 0.732655327388\n",
      "7 4 13.0 0.733657556998\n",
      "8 4 13.0 0.736731196214\n",
      "9 4 13.0 0.73837702971\n",
      "10 4 13.0 0.739981065581\n",
      "11 4 13.0 0.738863826522\n",
      "12 4 13.0 0.740111174796\n",
      "13 4 13.0 0.739939945276\n",
      "14 4 13.0 0.741443207133\n",
      "15 4 13.0 0.740993856877\n",
      "3 4 13.5 0.716063557883\n",
      "4 4 13.5 0.724995538778\n",
      "5 4 13.5 0.72814531547\n",
      "6 4 13.5 0.732655327388\n",
      "7 4 13.5 0.733657556998\n",
      "8 4 13.5 0.736731196214\n",
      "9 4 13.5 0.73837702971\n",
      "10 4 13.5 0.739981065581\n",
      "11 4 13.5 0.738863826522\n",
      "12 4 13.5 0.740111174796\n",
      "13 4 13.5 0.739939945276\n",
      "14 4 13.5 0.741443207133\n",
      "15 4 13.5 0.740993856877\n",
      "3 4 14.0 0.716063557883\n",
      "4 4 14.0 0.724995538778\n",
      "5 4 14.0 0.72814531547\n",
      "6 4 14.0 0.732655327388\n",
      "7 4 14.0 0.733657556998\n",
      "8 4 14.0 0.736731196214\n",
      "9 4 14.0 0.73837702971\n",
      "10 4 14.0 0.739981065581\n",
      "11 4 14.0 0.738863826522\n",
      "12 4 14.0 0.740111174796\n",
      "13 4 14.0 0.739939945276\n",
      "14 4 14.0 0.741443207133\n",
      "15 4 14.0 0.740993856877\n",
      "3 4 14.5 0.716063557883\n",
      "4 4 14.5 0.724995538778\n",
      "5 4 14.5 0.72814531547\n",
      "6 4 14.5 0.732655327388\n",
      "7 4 14.5 0.733657556998\n",
      "8 4 14.5 0.736731196214\n",
      "9 4 14.5 0.73837702971\n",
      "10 4 14.5 0.739981065581\n",
      "11 4 14.5 0.738863826522\n",
      "12 4 14.5 0.740111174796\n",
      "13 4 14.5 0.739939945276\n",
      "14 4 14.5 0.741443207133\n",
      "15 4 14.5 0.740993856877\n",
      "3 4 15.0 0.716063557883\n",
      "4 4 15.0 0.724995538778\n",
      "5 4 15.0 0.72814531547\n",
      "6 4 15.0 0.732655327388\n",
      "7 4 15.0 0.733657556998\n",
      "8 4 15.0 0.736731196214\n",
      "9 4 15.0 0.73837702971\n",
      "10 4 15.0 0.739981065581\n",
      "11 4 15.0 0.738863826522\n",
      "12 4 15.0 0.740111174796\n",
      "13 4 15.0 0.739939945276\n",
      "14 4 15.0 0.741443207133\n",
      "15 4 15.0 0.740993856877\n",
      "3 4 15.5 0.716063557883\n",
      "4 4 15.5 0.724995538778\n",
      "5 4 15.5 0.72814531547\n",
      "6 4 15.5 0.732655327388\n",
      "7 4 15.5 0.733657556998\n",
      "8 4 15.5 0.736731196214\n",
      "9 4 15.5 0.73837702971\n",
      "10 4 15.5 0.739981065581\n",
      "11 4 15.5 0.738863826522\n",
      "12 4 15.5 0.740111174796\n",
      "13 4 15.5 0.739939945276\n",
      "14 4 15.5 0.741443207133\n",
      "15 4 15.5 0.740993856877\n",
      "3 4 16.0 0.716063557883\n",
      "4 4 16.0 0.724995538778\n",
      "5 4 16.0 0.72814531547\n",
      "6 4 16.0 0.732655327388\n",
      "7 4 16.0 0.733657556998\n",
      "8 4 16.0 0.736731196214\n",
      "9 4 16.0 0.73837702971\n",
      "10 4 16.0 0.739981065581\n",
      "11 4 16.0 0.738863826522\n",
      "12 4 16.0 0.740111174796\n",
      "13 4 16.0 0.739939945276\n",
      "14 4 16.0 0.741443207133\n",
      "15 4 16.0 0.740993856877\n",
      "3 4 16.5 0.716063557883\n",
      "4 4 16.5 0.724995538778\n",
      "5 4 16.5 0.72814531547\n",
      "6 4 16.5 0.732655327388\n",
      "7 4 16.5 0.733657556998\n",
      "8 4 16.5 0.736731196214\n",
      "9 4 16.5 0.73837702971\n",
      "10 4 16.5 0.739981065581\n",
      "11 4 16.5 0.738863826522\n",
      "12 4 16.5 0.740111174796\n",
      "13 4 16.5 0.739939945276\n",
      "14 4 16.5 0.741443207133\n",
      "15 4 16.5 0.740993856877\n",
      "3 4 17.0 0.716063557883\n",
      "4 4 17.0 0.724995538778\n",
      "5 4 17.0 0.72814531547\n",
      "6 4 17.0 0.732655327388\n",
      "7 4 17.0 0.733657556998\n",
      "8 4 17.0 0.736731196214\n",
      "9 4 17.0 0.73837702971\n",
      "10 4 17.0 0.739981065581\n",
      "11 4 17.0 0.738863826522\n",
      "12 4 17.0 0.740111174796\n",
      "13 4 17.0 0.739939945276\n",
      "14 4 17.0 0.741443207133\n",
      "15 4 17.0 0.740993856877\n",
      "3 4 17.5 0.716063557883\n",
      "4 4 17.5 0.724995538778\n",
      "5 4 17.5 0.72814531547\n",
      "6 4 17.5 0.732655327388\n",
      "7 4 17.5 0.733657556998\n",
      "8 4 17.5 0.736731196214\n",
      "9 4 17.5 0.73837702971\n",
      "10 4 17.5 0.739981065581\n",
      "11 4 17.5 0.738863826522\n",
      "12 4 17.5 0.740111174796\n",
      "13 4 17.5 0.739939945276\n",
      "14 4 17.5 0.741443207133\n",
      "15 4 17.5 0.740993856877\n",
      "3 4.5 12 0.716063557883\n",
      "4 4.5 12 0.724995538778\n",
      "5 4.5 12 0.72814531547\n",
      "6 4.5 12 0.732655327388\n",
      "7 4.5 12 0.733657556998\n",
      "8 4.5 12 0.736731196214\n",
      "9 4.5 12 0.73837702971\n",
      "10 4.5 12 0.739981065581\n",
      "11 4.5 12 0.738863826522\n",
      "12 4.5 12 0.740111174796\n",
      "13 4.5 12 0.739939945276\n",
      "14 4.5 12 0.741443207133\n",
      "15 4.5 12 0.740993856877\n",
      "3 4.5 12.5 0.716063557883\n",
      "4 4.5 12.5 0.724995538778\n",
      "5 4.5 12.5 0.72814531547\n",
      "6 4.5 12.5 0.732655327388\n",
      "7 4.5 12.5 0.733657556998\n",
      "8 4.5 12.5 0.736731196214\n",
      "9 4.5 12.5 0.73837702971\n",
      "10 4.5 12.5 0.739981065581\n",
      "11 4.5 12.5 0.738863826522\n",
      "12 4.5 12.5 0.740111174796\n",
      "13 4.5 12.5 0.739939945276\n",
      "14 4.5 12.5 0.741443207133\n",
      "15 4.5 12.5 0.740993856877\n",
      "3 4.5 13.0 0.716063557883\n",
      "4 4.5 13.0 0.724995538778\n",
      "5 4.5 13.0 0.72814531547\n",
      "6 4.5 13.0 0.732655327388\n",
      "7 4.5 13.0 0.733657556998\n",
      "8 4.5 13.0 0.736731196214\n",
      "9 4.5 13.0 0.73837702971\n",
      "10 4.5 13.0 0.739981065581\n",
      "11 4.5 13.0 0.738863826522\n",
      "12 4.5 13.0 0.740111174796\n",
      "13 4.5 13.0 0.739939945276\n",
      "14 4.5 13.0 0.741443207133\n",
      "15 4.5 13.0 0.740993856877\n",
      "3 4.5 13.5 0.716063557883\n",
      "4 4.5 13.5 0.724995538778\n",
      "5 4.5 13.5 0.72814531547\n",
      "6 4.5 13.5 0.732655327388\n",
      "7 4.5 13.5 0.733657556998\n",
      "8 4.5 13.5 0.736731196214\n",
      "9 4.5 13.5 0.73837702971\n",
      "10 4.5 13.5 0.739981065581\n",
      "11 4.5 13.5 0.738863826522\n",
      "12 4.5 13.5 0.740111174796\n",
      "13 4.5 13.5 0.739939945276\n",
      "14 4.5 13.5 0.741443207133\n",
      "15 4.5 13.5 0.740993856877\n",
      "3 4.5 14.0 0.716063557883\n",
      "4 4.5 14.0 0.724995538778\n",
      "5 4.5 14.0 0.72814531547\n",
      "6 4.5 14.0 0.732655327388\n",
      "7 4.5 14.0 0.733657556998\n",
      "8 4.5 14.0 0.736731196214\n",
      "9 4.5 14.0 0.73837702971\n",
      "10 4.5 14.0 0.739981065581\n",
      "11 4.5 14.0 0.738863826522\n",
      "12 4.5 14.0 0.740111174796\n",
      "13 4.5 14.0 0.739939945276\n",
      "14 4.5 14.0 0.741443207133\n",
      "15 4.5 14.0 0.740993856877\n",
      "3 4.5 14.5 0.716063557883\n",
      "4 4.5 14.5 0.724995538778\n",
      "5 4.5 14.5 0.72814531547\n",
      "6 4.5 14.5 0.732655327388\n",
      "7 4.5 14.5 0.733657556998\n",
      "8 4.5 14.5 0.736731196214\n",
      "9 4.5 14.5 0.73837702971\n",
      "10 4.5 14.5 0.739981065581\n",
      "11 4.5 14.5 0.738863826522\n",
      "12 4.5 14.5 0.740111174796\n",
      "13 4.5 14.5 0.739939945276\n",
      "14 4.5 14.5 0.741443207133\n",
      "15 4.5 14.5 0.740993856877\n",
      "3 4.5 15.0 0.716063557883\n",
      "4 4.5 15.0 0.724995538778\n",
      "5 4.5 15.0 0.72814531547\n",
      "6 4.5 15.0 0.732655327388\n",
      "7 4.5 15.0 0.733657556998\n",
      "8 4.5 15.0 0.736731196214\n",
      "9 4.5 15.0 0.73837702971\n",
      "10 4.5 15.0 0.739981065581\n",
      "11 4.5 15.0 0.738863826522\n",
      "12 4.5 15.0 0.740111174796\n",
      "13 4.5 15.0 0.739939945276\n",
      "14 4.5 15.0 0.741443207133\n",
      "15 4.5 15.0 0.740993856877\n",
      "3 4.5 15.5 0.716063557883\n",
      "4 4.5 15.5 0.724995538778\n",
      "5 4.5 15.5 0.72814531547\n",
      "6 4.5 15.5 0.732655327388\n",
      "7 4.5 15.5 0.733657556998\n",
      "8 4.5 15.5 0.736731196214\n",
      "9 4.5 15.5 0.73837702971\n",
      "10 4.5 15.5 0.739981065581\n",
      "11 4.5 15.5 0.738863826522\n",
      "12 4.5 15.5 0.740111174796\n",
      "13 4.5 15.5 0.739939945276\n",
      "14 4.5 15.5 0.741443207133\n",
      "15 4.5 15.5 0.740993856877\n",
      "3 4.5 16.0 0.716063557883\n",
      "4 4.5 16.0 0.724995538778\n",
      "5 4.5 16.0 0.72814531547\n",
      "6 4.5 16.0 0.732655327388\n",
      "7 4.5 16.0 0.733657556998\n",
      "8 4.5 16.0 0.736731196214\n",
      "9 4.5 16.0 0.73837702971\n",
      "10 4.5 16.0 0.739981065581\n",
      "11 4.5 16.0 0.738863826522\n",
      "12 4.5 16.0 0.740111174796\n",
      "13 4.5 16.0 0.739939945276\n",
      "14 4.5 16.0 0.741443207133\n",
      "15 4.5 16.0 0.740993856877\n",
      "3 4.5 16.5 0.716063557883\n",
      "4 4.5 16.5 0.724995538778\n",
      "5 4.5 16.5 0.72814531547\n",
      "6 4.5 16.5 0.732655327388\n",
      "7 4.5 16.5 0.733657556998\n",
      "8 4.5 16.5 0.736731196214\n",
      "9 4.5 16.5 0.73837702971\n",
      "10 4.5 16.5 0.739981065581\n",
      "11 4.5 16.5 0.738863826522\n",
      "12 4.5 16.5 0.740111174796\n",
      "13 4.5 16.5 0.739939945276\n",
      "14 4.5 16.5 0.741443207133\n",
      "15 4.5 16.5 0.740993856877\n",
      "3 4.5 17.0 0.716063557883\n",
      "4 4.5 17.0 0.724995538778\n",
      "5 4.5 17.0 0.72814531547\n",
      "6 4.5 17.0 0.732655327388\n",
      "7 4.5 17.0 0.733657556998\n",
      "8 4.5 17.0 0.736731196214\n",
      "9 4.5 17.0 0.73837702971\n",
      "10 4.5 17.0 0.739981065581\n",
      "11 4.5 17.0 0.738863826522\n",
      "12 4.5 17.0 0.740111174796\n",
      "13 4.5 17.0 0.739939945276\n",
      "14 4.5 17.0 0.741443207133\n",
      "15 4.5 17.0 0.740993856877\n",
      "3 4.5 17.5 0.716063557883\n",
      "4 4.5 17.5 0.724995538778\n",
      "5 4.5 17.5 0.72814531547\n",
      "6 4.5 17.5 0.732655327388\n",
      "7 4.5 17.5 0.733657556998\n",
      "8 4.5 17.5 0.736731196214\n",
      "9 4.5 17.5 0.73837702971\n",
      "10 4.5 17.5 0.739981065581\n",
      "11 4.5 17.5 0.738863826522\n",
      "12 4.5 17.5 0.740111174796\n",
      "13 4.5 17.5 0.739939945276\n",
      "14 4.5 17.5 0.741443207133\n",
      "15 4.5 17.5 0.740993856877\n",
      "3 5.0 12 0.716063557883\n",
      "4 5.0 12 0.724995538778\n",
      "5 5.0 12 0.72814531547\n",
      "6 5.0 12 0.732655327388\n",
      "7 5.0 12 0.733657556998\n",
      "8 5.0 12 0.736731196214\n",
      "9 5.0 12 0.73837702971\n",
      "10 5.0 12 0.739981065581\n",
      "11 5.0 12 0.738863826522\n",
      "12 5.0 12 0.740111174796\n",
      "13 5.0 12 0.739939945276\n",
      "14 5.0 12 0.741443207133\n",
      "15 5.0 12 0.740993856877\n",
      "3 5.0 12.5 0.716063557883\n",
      "4 5.0 12.5 0.724995538778\n",
      "5 5.0 12.5 0.72814531547\n",
      "6 5.0 12.5 0.732655327388\n",
      "7 5.0 12.5 0.733657556998\n",
      "8 5.0 12.5 0.736731196214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 5.0 12.5 0.73837702971\n",
      "10 5.0 12.5 0.739981065581\n",
      "11 5.0 12.5 0.738863826522\n",
      "12 5.0 12.5 0.740111174796\n",
      "13 5.0 12.5 0.739939945276\n",
      "14 5.0 12.5 0.741443207133\n",
      "15 5.0 12.5 0.740993856877\n",
      "3 5.0 13.0 0.716063557883\n",
      "4 5.0 13.0 0.724995538778\n",
      "5 5.0 13.0 0.72814531547\n",
      "6 5.0 13.0 0.732655327388\n",
      "7 5.0 13.0 0.733657556998\n",
      "8 5.0 13.0 0.736731196214\n",
      "9 5.0 13.0 0.73837702971\n",
      "10 5.0 13.0 0.739981065581\n",
      "11 5.0 13.0 0.738863826522\n",
      "12 5.0 13.0 0.740111174796\n",
      "13 5.0 13.0 0.739939945276\n",
      "14 5.0 13.0 0.741443207133\n",
      "15 5.0 13.0 0.740993856877\n",
      "3 5.0 13.5 0.716063557883\n",
      "4 5.0 13.5 0.724995538778\n",
      "5 5.0 13.5 0.72814531547\n",
      "6 5.0 13.5 0.732655327388\n",
      "7 5.0 13.5 0.733657556998\n",
      "8 5.0 13.5 0.736731196214\n",
      "9 5.0 13.5 0.73837702971\n",
      "10 5.0 13.5 0.739981065581\n",
      "11 5.0 13.5 0.738863826522\n",
      "12 5.0 13.5 0.740111174796\n",
      "13 5.0 13.5 0.739939945276\n",
      "14 5.0 13.5 0.741443207133\n",
      "15 5.0 13.5 0.740993856877\n",
      "3 5.0 14.0 0.716063557883\n",
      "4 5.0 14.0 0.724995538778\n",
      "5 5.0 14.0 0.72814531547\n",
      "6 5.0 14.0 0.732655327388\n",
      "7 5.0 14.0 0.733657556998\n",
      "8 5.0 14.0 0.736731196214\n",
      "9 5.0 14.0 0.73837702971\n",
      "10 5.0 14.0 0.739981065581\n",
      "11 5.0 14.0 0.738863826522\n",
      "12 5.0 14.0 0.740111174796\n",
      "13 5.0 14.0 0.739939945276\n",
      "14 5.0 14.0 0.741443207133\n",
      "15 5.0 14.0 0.740993856877\n",
      "3 5.0 14.5 0.716063557883\n",
      "4 5.0 14.5 0.724995538778\n",
      "5 5.0 14.5 0.72814531547\n",
      "6 5.0 14.5 0.732655327388\n",
      "7 5.0 14.5 0.733657556998\n",
      "8 5.0 14.5 0.736731196214\n",
      "9 5.0 14.5 0.73837702971\n",
      "10 5.0 14.5 0.739981065581\n",
      "11 5.0 14.5 0.738863826522\n",
      "12 5.0 14.5 0.740111174796\n",
      "13 5.0 14.5 0.739939945276\n",
      "14 5.0 14.5 0.741443207133\n",
      "15 5.0 14.5 0.740993856877\n",
      "3 5.0 15.0 0.716063557883\n",
      "4 5.0 15.0 0.724995538778\n",
      "5 5.0 15.0 0.72814531547\n",
      "6 5.0 15.0 0.732655327388\n",
      "7 5.0 15.0 0.733657556998\n",
      "8 5.0 15.0 0.736731196214\n",
      "9 5.0 15.0 0.73837702971\n",
      "10 5.0 15.0 0.739981065581\n",
      "11 5.0 15.0 0.738863826522\n",
      "12 5.0 15.0 0.740111174796\n",
      "13 5.0 15.0 0.739939945276\n",
      "14 5.0 15.0 0.741443207133\n",
      "15 5.0 15.0 0.740993856877\n",
      "3 5.0 15.5 0.716063557883\n",
      "4 5.0 15.5 0.724995538778\n",
      "5 5.0 15.5 0.72814531547\n",
      "6 5.0 15.5 0.732655327388\n",
      "7 5.0 15.5 0.733657556998\n",
      "8 5.0 15.5 0.736731196214\n",
      "9 5.0 15.5 0.73837702971\n",
      "10 5.0 15.5 0.739981065581\n",
      "11 5.0 15.5 0.738863826522\n",
      "12 5.0 15.5 0.740111174796\n",
      "13 5.0 15.5 0.739939945276\n",
      "14 5.0 15.5 0.741443207133\n",
      "15 5.0 15.5 0.740993856877\n",
      "3 5.0 16.0 0.716063557883\n",
      "4 5.0 16.0 0.724995538778\n",
      "5 5.0 16.0 0.72814531547\n",
      "6 5.0 16.0 0.732655327388\n",
      "7 5.0 16.0 0.733657556998\n",
      "8 5.0 16.0 0.736731196214\n",
      "9 5.0 16.0 0.73837702971\n",
      "10 5.0 16.0 0.739981065581\n",
      "11 5.0 16.0 0.738863826522\n",
      "12 5.0 16.0 0.740111174796\n",
      "13 5.0 16.0 0.739939945276\n",
      "14 5.0 16.0 0.741443207133\n",
      "15 5.0 16.0 0.740993856877\n",
      "3 5.0 16.5 0.716063557883\n",
      "4 5.0 16.5 0.724995538778\n",
      "5 5.0 16.5 0.72814531547\n",
      "6 5.0 16.5 0.732655327388\n",
      "7 5.0 16.5 0.733657556998\n",
      "8 5.0 16.5 0.736731196214\n",
      "9 5.0 16.5 0.73837702971\n",
      "10 5.0 16.5 0.739981065581\n",
      "11 5.0 16.5 0.738863826522\n",
      "12 5.0 16.5 0.740111174796\n",
      "13 5.0 16.5 0.739939945276\n",
      "14 5.0 16.5 0.741443207133\n",
      "15 5.0 16.5 0.740993856877\n",
      "3 5.0 17.0 0.716063557883\n",
      "4 5.0 17.0 0.724995538778\n",
      "5 5.0 17.0 0.72814531547\n",
      "6 5.0 17.0 0.732655327388\n",
      "7 5.0 17.0 0.733657556998\n",
      "8 5.0 17.0 0.736731196214\n",
      "9 5.0 17.0 0.73837702971\n",
      "10 5.0 17.0 0.739981065581\n",
      "11 5.0 17.0 0.738863826522\n",
      "12 5.0 17.0 0.740111174796\n",
      "13 5.0 17.0 0.739939945276\n",
      "14 5.0 17.0 0.741443207133\n",
      "15 5.0 17.0 0.740993856877\n",
      "3 5.0 17.5 0.716063557883\n",
      "4 5.0 17.5 0.724995538778\n",
      "5 5.0 17.5 0.72814531547\n",
      "6 5.0 17.5 0.732655327388\n",
      "7 5.0 17.5 0.733657556998\n",
      "8 5.0 17.5 0.736731196214\n",
      "9 5.0 17.5 0.73837702971\n",
      "10 5.0 17.5 0.739981065581\n",
      "11 5.0 17.5 0.738863826522\n",
      "12 5.0 17.5 0.740111174796\n",
      "13 5.0 17.5 0.739939945276\n",
      "14 5.0 17.5 0.741443207133\n",
      "15 5.0 17.5 0.740993856877\n",
      "3 5.5 12 0.716063557883\n",
      "4 5.5 12 0.724995538778\n",
      "5 5.5 12 0.72814531547\n",
      "6 5.5 12 0.732655327388\n",
      "7 5.5 12 0.733657556998\n",
      "8 5.5 12 0.736731196214\n",
      "9 5.5 12 0.73837702971\n",
      "10 5.5 12 0.739981065581\n",
      "11 5.5 12 0.738863826522\n",
      "12 5.5 12 0.740111174796\n",
      "13 5.5 12 0.739939945276\n",
      "14 5.5 12 0.741443207133\n",
      "15 5.5 12 0.740993856877\n",
      "3 5.5 12.5 0.716063557883\n",
      "4 5.5 12.5 0.724995538778\n",
      "5 5.5 12.5 0.72814531547\n",
      "6 5.5 12.5 0.732655327388\n",
      "7 5.5 12.5 0.733657556998\n",
      "8 5.5 12.5 0.736731196214\n",
      "9 5.5 12.5 0.73837702971\n",
      "10 5.5 12.5 0.739981065581\n",
      "11 5.5 12.5 0.738863826522\n",
      "12 5.5 12.5 0.740111174796\n",
      "13 5.5 12.5 0.739939945276\n",
      "14 5.5 12.5 0.741443207133\n",
      "15 5.5 12.5 0.740993856877\n",
      "3 5.5 13.0 0.716063557883\n",
      "4 5.5 13.0 0.724995538778\n",
      "5 5.5 13.0 0.72814531547\n",
      "6 5.5 13.0 0.732655327388\n",
      "7 5.5 13.0 0.733657556998\n",
      "8 5.5 13.0 0.736731196214\n",
      "9 5.5 13.0 0.73837702971\n",
      "10 5.5 13.0 0.739981065581\n",
      "11 5.5 13.0 0.738863826522\n",
      "12 5.5 13.0 0.740111174796\n",
      "13 5.5 13.0 0.739939945276\n",
      "14 5.5 13.0 0.741443207133\n",
      "15 5.5 13.0 0.740993856877\n",
      "3 5.5 13.5 0.716063557883\n",
      "4 5.5 13.5 0.724995538778\n",
      "5 5.5 13.5 0.72814531547\n",
      "6 5.5 13.5 0.732655327388\n",
      "7 5.5 13.5 0.733657556998\n",
      "8 5.5 13.5 0.736731196214\n",
      "9 5.5 13.5 0.73837702971\n",
      "10 5.5 13.5 0.739981065581\n",
      "11 5.5 13.5 0.738863826522\n",
      "12 5.5 13.5 0.740111174796\n",
      "13 5.5 13.5 0.739939945276\n",
      "14 5.5 13.5 0.741443207133\n",
      "15 5.5 13.5 0.740993856877\n",
      "3 5.5 14.0 0.716063557883\n",
      "4 5.5 14.0 0.724995538778\n",
      "5 5.5 14.0 0.72814531547\n",
      "6 5.5 14.0 0.732655327388\n",
      "7 5.5 14.0 0.733657556998\n",
      "8 5.5 14.0 0.736731196214\n",
      "9 5.5 14.0 0.73837702971\n",
      "10 5.5 14.0 0.739981065581\n",
      "11 5.5 14.0 0.738863826522\n",
      "12 5.5 14.0 0.740111174796\n",
      "13 5.5 14.0 0.739939945276\n",
      "14 5.5 14.0 0.741443207133\n",
      "15 5.5 14.0 0.740993856877\n",
      "3 5.5 14.5 0.716063557883\n",
      "4 5.5 14.5 0.724995538778\n",
      "5 5.5 14.5 0.72814531547\n",
      "6 5.5 14.5 0.732655327388\n",
      "7 5.5 14.5 0.733657556998\n",
      "8 5.5 14.5 0.736731196214\n",
      "9 5.5 14.5 0.73837702971\n",
      "10 5.5 14.5 0.739981065581\n",
      "11 5.5 14.5 0.738863826522\n",
      "12 5.5 14.5 0.740111174796\n",
      "13 5.5 14.5 0.739939945276\n",
      "14 5.5 14.5 0.741443207133\n",
      "15 5.5 14.5 0.740993856877\n",
      "3 5.5 15.0 0.716063557883\n",
      "4 5.5 15.0 0.724995538778\n",
      "5 5.5 15.0 0.72814531547\n",
      "6 5.5 15.0 0.732655327388\n",
      "7 5.5 15.0 0.733657556998\n",
      "8 5.5 15.0 0.736731196214\n",
      "9 5.5 15.0 0.73837702971\n",
      "10 5.5 15.0 0.739981065581\n",
      "11 5.5 15.0 0.738863826522\n",
      "12 5.5 15.0 0.740111174796\n",
      "13 5.5 15.0 0.739939945276\n",
      "14 5.5 15.0 0.741443207133\n",
      "15 5.5 15.0 0.740993856877\n",
      "3 5.5 15.5 0.716063557883\n",
      "4 5.5 15.5 0.724995538778\n",
      "5 5.5 15.5 0.72814531547\n",
      "6 5.5 15.5 0.732655327388\n",
      "7 5.5 15.5 0.733657556998\n",
      "8 5.5 15.5 0.736731196214\n",
      "9 5.5 15.5 0.73837702971\n",
      "10 5.5 15.5 0.739981065581\n",
      "11 5.5 15.5 0.738863826522\n",
      "12 5.5 15.5 0.740111174796\n",
      "13 5.5 15.5 0.739939945276\n",
      "14 5.5 15.5 0.741443207133\n",
      "15 5.5 15.5 0.740993856877\n",
      "3 5.5 16.0 0.716063557883\n",
      "4 5.5 16.0 0.724995538778\n",
      "5 5.5 16.0 0.72814531547\n",
      "6 5.5 16.0 0.732655327388\n",
      "7 5.5 16.0 0.733657556998\n",
      "8 5.5 16.0 0.736731196214\n",
      "9 5.5 16.0 0.73837702971\n",
      "10 5.5 16.0 0.739981065581\n",
      "11 5.5 16.0 0.738863826522\n",
      "12 5.5 16.0 0.740111174796\n",
      "13 5.5 16.0 0.739939945276\n",
      "14 5.5 16.0 0.741443207133\n",
      "15 5.5 16.0 0.740993856877\n",
      "3 5.5 16.5 0.716063557883\n",
      "4 5.5 16.5 0.724995538778\n",
      "5 5.5 16.5 0.72814531547\n",
      "6 5.5 16.5 0.732655327388\n",
      "7 5.5 16.5 0.733657556998\n",
      "8 5.5 16.5 0.736731196214\n",
      "9 5.5 16.5 0.73837702971\n",
      "10 5.5 16.5 0.739981065581\n",
      "11 5.5 16.5 0.738863826522\n",
      "12 5.5 16.5 0.740111174796\n",
      "13 5.5 16.5 0.739939945276\n",
      "14 5.5 16.5 0.741443207133\n",
      "15 5.5 16.5 0.740993856877\n",
      "3 5.5 17.0 0.716063557883\n",
      "4 5.5 17.0 0.724995538778\n",
      "5 5.5 17.0 0.72814531547\n",
      "6 5.5 17.0 0.732655327388\n",
      "7 5.5 17.0 0.733657556998\n",
      "8 5.5 17.0 0.736731196214\n",
      "9 5.5 17.0 0.73837702971\n",
      "10 5.5 17.0 0.739981065581\n",
      "11 5.5 17.0 0.738863826522\n",
      "12 5.5 17.0 0.740111174796\n",
      "13 5.5 17.0 0.739939945276\n",
      "14 5.5 17.0 0.741443207133\n",
      "15 5.5 17.0 0.740993856877\n",
      "3 5.5 17.5 0.716063557883\n",
      "4 5.5 17.5 0.724995538778\n",
      "5 5.5 17.5 0.72814531547\n",
      "6 5.5 17.5 0.732655327388\n",
      "7 5.5 17.5 0.733657556998\n",
      "8 5.5 17.5 0.736731196214\n",
      "9 5.5 17.5 0.73837702971\n",
      "10 5.5 17.5 0.739981065581\n",
      "11 5.5 17.5 0.738863826522\n",
      "12 5.5 17.5 0.740111174796\n",
      "13 5.5 17.5 0.739939945276\n",
      "14 5.5 17.5 0.741443207133\n",
      "15 5.5 17.5 0.740993856877\n",
      "3 6.0 12 0.716063557883\n",
      "4 6.0 12 0.724995538778\n",
      "5 6.0 12 0.72814531547\n",
      "6 6.0 12 0.732655327388\n",
      "7 6.0 12 0.733657556998\n",
      "8 6.0 12 0.736731196214\n",
      "9 6.0 12 0.73837702971\n",
      "10 6.0 12 0.739981065581\n",
      "11 6.0 12 0.738863826522\n",
      "12 6.0 12 0.740111174796\n",
      "13 6.0 12 0.739939945276\n",
      "14 6.0 12 0.741443207133\n",
      "15 6.0 12 0.740993856877\n",
      "3 6.0 12.5 0.716063557883\n",
      "4 6.0 12.5 0.724995538778\n",
      "5 6.0 12.5 0.72814531547\n",
      "6 6.0 12.5 0.732655327388\n",
      "7 6.0 12.5 0.733657556998\n",
      "8 6.0 12.5 0.736731196214\n",
      "9 6.0 12.5 0.73837702971\n",
      "10 6.0 12.5 0.739981065581\n",
      "11 6.0 12.5 0.738863826522\n",
      "12 6.0 12.5 0.740111174796\n",
      "13 6.0 12.5 0.739939945276\n",
      "14 6.0 12.5 0.741443207133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 6.0 12.5 0.740993856877\n",
      "3 6.0 13.0 0.716063557883\n",
      "4 6.0 13.0 0.724995538778\n",
      "5 6.0 13.0 0.72814531547\n",
      "6 6.0 13.0 0.732655327388\n",
      "7 6.0 13.0 0.733657556998\n",
      "8 6.0 13.0 0.736731196214\n",
      "9 6.0 13.0 0.73837702971\n",
      "10 6.0 13.0 0.739981065581\n",
      "11 6.0 13.0 0.738863826522\n",
      "12 6.0 13.0 0.740111174796\n",
      "13 6.0 13.0 0.739939945276\n",
      "14 6.0 13.0 0.741443207133\n",
      "15 6.0 13.0 0.740993856877\n",
      "3 6.0 13.5 0.716063557883\n",
      "4 6.0 13.5 0.724995538778\n",
      "5 6.0 13.5 0.72814531547\n",
      "6 6.0 13.5 0.732655327388\n",
      "7 6.0 13.5 0.733657556998\n",
      "8 6.0 13.5 0.736731196214\n",
      "9 6.0 13.5 0.73837702971\n",
      "10 6.0 13.5 0.739981065581\n",
      "11 6.0 13.5 0.738863826522\n",
      "12 6.0 13.5 0.740111174796\n",
      "13 6.0 13.5 0.739939945276\n",
      "14 6.0 13.5 0.741443207133\n",
      "15 6.0 13.5 0.740993856877\n",
      "3 6.0 14.0 0.716063557883\n",
      "4 6.0 14.0 0.724995538778\n",
      "5 6.0 14.0 0.72814531547\n",
      "6 6.0 14.0 0.732655327388\n",
      "7 6.0 14.0 0.733657556998\n",
      "8 6.0 14.0 0.736731196214\n",
      "9 6.0 14.0 0.73837702971\n",
      "10 6.0 14.0 0.739981065581\n",
      "11 6.0 14.0 0.738863826522\n",
      "12 6.0 14.0 0.740111174796\n",
      "13 6.0 14.0 0.739939945276\n",
      "14 6.0 14.0 0.741443207133\n",
      "15 6.0 14.0 0.740993856877\n",
      "3 6.0 14.5 0.716063557883\n",
      "4 6.0 14.5 0.724995538778\n",
      "5 6.0 14.5 0.72814531547\n",
      "6 6.0 14.5 0.732655327388\n",
      "7 6.0 14.5 0.733657556998\n",
      "8 6.0 14.5 0.736731196214\n",
      "9 6.0 14.5 0.73837702971\n",
      "10 6.0 14.5 0.739981065581\n",
      "11 6.0 14.5 0.738863826522\n",
      "12 6.0 14.5 0.740111174796\n",
      "13 6.0 14.5 0.739939945276\n",
      "14 6.0 14.5 0.741443207133\n",
      "15 6.0 14.5 0.740993856877\n",
      "3 6.0 15.0 0.716063557883\n",
      "4 6.0 15.0 0.724995538778\n",
      "5 6.0 15.0 0.72814531547\n",
      "6 6.0 15.0 0.732655327388\n",
      "7 6.0 15.0 0.733657556998\n",
      "8 6.0 15.0 0.736731196214\n",
      "9 6.0 15.0 0.73837702971\n",
      "10 6.0 15.0 0.739981065581\n",
      "11 6.0 15.0 0.738863826522\n",
      "12 6.0 15.0 0.740111174796\n",
      "13 6.0 15.0 0.739939945276\n",
      "14 6.0 15.0 0.741443207133\n",
      "15 6.0 15.0 0.740993856877\n",
      "3 6.0 15.5 0.716063557883\n",
      "4 6.0 15.5 0.724995538778\n",
      "5 6.0 15.5 0.72814531547\n",
      "6 6.0 15.5 0.732655327388\n",
      "7 6.0 15.5 0.733657556998\n",
      "8 6.0 15.5 0.736731196214\n",
      "9 6.0 15.5 0.73837702971\n",
      "10 6.0 15.5 0.739981065581\n",
      "11 6.0 15.5 0.738863826522\n",
      "12 6.0 15.5 0.740111174796\n",
      "13 6.0 15.5 0.739939945276\n",
      "14 6.0 15.5 0.741443207133\n",
      "15 6.0 15.5 0.740993856877\n",
      "3 6.0 16.0 0.716063557883\n",
      "4 6.0 16.0 0.724995538778\n",
      "5 6.0 16.0 0.72814531547\n",
      "6 6.0 16.0 0.732655327388\n",
      "7 6.0 16.0 0.733657556998\n",
      "8 6.0 16.0 0.736731196214\n",
      "9 6.0 16.0 0.73837702971\n",
      "10 6.0 16.0 0.739981065581\n",
      "11 6.0 16.0 0.738863826522\n",
      "12 6.0 16.0 0.740111174796\n",
      "13 6.0 16.0 0.739939945276\n",
      "14 6.0 16.0 0.741443207133\n",
      "15 6.0 16.0 0.740993856877\n",
      "3 6.0 16.5 0.716063557883\n",
      "4 6.0 16.5 0.724995538778\n",
      "5 6.0 16.5 0.72814531547\n",
      "6 6.0 16.5 0.732655327388\n",
      "7 6.0 16.5 0.733657556998\n",
      "8 6.0 16.5 0.736731196214\n",
      "9 6.0 16.5 0.73837702971\n",
      "10 6.0 16.5 0.739981065581\n",
      "11 6.0 16.5 0.738863826522\n",
      "12 6.0 16.5 0.740111174796\n",
      "13 6.0 16.5 0.739939945276\n",
      "14 6.0 16.5 0.741443207133\n",
      "15 6.0 16.5 0.740993856877\n",
      "3 6.0 17.0 0.716063557883\n",
      "4 6.0 17.0 0.724995538778\n",
      "5 6.0 17.0 0.72814531547\n",
      "6 6.0 17.0 0.732655327388\n",
      "7 6.0 17.0 0.733657556998\n",
      "8 6.0 17.0 0.736731196214\n",
      "9 6.0 17.0 0.73837702971\n",
      "10 6.0 17.0 0.739981065581\n",
      "11 6.0 17.0 0.738863826522\n",
      "12 6.0 17.0 0.740111174796\n",
      "13 6.0 17.0 0.739939945276\n",
      "14 6.0 17.0 0.741443207133\n",
      "15 6.0 17.0 0.740993856877\n",
      "3 6.0 17.5 0.716063557883\n",
      "4 6.0 17.5 0.724995538778\n",
      "5 6.0 17.5 0.72814531547\n",
      "6 6.0 17.5 0.732655327388\n",
      "7 6.0 17.5 0.733657556998\n",
      "8 6.0 17.5 0.736731196214\n",
      "9 6.0 17.5 0.73837702971\n",
      "10 6.0 17.5 0.739981065581\n",
      "11 6.0 17.5 0.738863826522\n",
      "12 6.0 17.5 0.740111174796\n",
      "13 6.0 17.5 0.739939945276\n",
      "14 6.0 17.5 0.741443207133\n",
      "15 6.0 17.5 0.740993856877\n",
      "3 6.5 12 0.716063557883\n",
      "4 6.5 12 0.724995538778\n",
      "5 6.5 12 0.72814531547\n",
      "6 6.5 12 0.732655327388\n",
      "7 6.5 12 0.733657556998\n",
      "8 6.5 12 0.736731196214\n",
      "9 6.5 12 0.73837702971\n",
      "10 6.5 12 0.739981065581\n",
      "11 6.5 12 0.738863826522\n",
      "12 6.5 12 0.740111174796\n",
      "13 6.5 12 0.739939945276\n",
      "14 6.5 12 0.741443207133\n",
      "15 6.5 12 0.740993856877\n",
      "3 6.5 12.5 0.716063557883\n",
      "4 6.5 12.5 0.724995538778\n",
      "5 6.5 12.5 0.72814531547\n",
      "6 6.5 12.5 0.732655327388\n",
      "7 6.5 12.5 0.733657556998\n",
      "8 6.5 12.5 0.736731196214\n",
      "9 6.5 12.5 0.73837702971\n",
      "10 6.5 12.5 0.739981065581\n",
      "11 6.5 12.5 0.738863826522\n",
      "12 6.5 12.5 0.740111174796\n",
      "13 6.5 12.5 0.739939945276\n",
      "14 6.5 12.5 0.741443207133\n",
      "15 6.5 12.5 0.740993856877\n",
      "3 6.5 13.0 0.716063557883\n",
      "4 6.5 13.0 0.724995538778\n",
      "5 6.5 13.0 0.72814531547\n",
      "6 6.5 13.0 0.732655327388\n",
      "7 6.5 13.0 0.733657556998\n",
      "8 6.5 13.0 0.736731196214\n",
      "9 6.5 13.0 0.73837702971\n",
      "10 6.5 13.0 0.739981065581\n",
      "11 6.5 13.0 0.738863826522\n",
      "12 6.5 13.0 0.740111174796\n",
      "13 6.5 13.0 0.739939945276\n",
      "14 6.5 13.0 0.741443207133\n",
      "15 6.5 13.0 0.740993856877\n",
      "3 6.5 13.5 0.716063557883\n",
      "4 6.5 13.5 0.724995538778\n",
      "5 6.5 13.5 0.72814531547\n",
      "6 6.5 13.5 0.732655327388\n",
      "7 6.5 13.5 0.733657556998\n",
      "8 6.5 13.5 0.736731196214\n",
      "9 6.5 13.5 0.73837702971\n",
      "10 6.5 13.5 0.739981065581\n",
      "11 6.5 13.5 0.738863826522\n",
      "12 6.5 13.5 0.740111174796\n",
      "13 6.5 13.5 0.739939945276\n",
      "14 6.5 13.5 0.741443207133\n",
      "15 6.5 13.5 0.740993856877\n",
      "3 6.5 14.0 0.716063557883\n",
      "4 6.5 14.0 0.724995538778\n",
      "5 6.5 14.0 0.72814531547\n",
      "6 6.5 14.0 0.732655327388\n",
      "7 6.5 14.0 0.733657556998\n",
      "8 6.5 14.0 0.736731196214\n",
      "9 6.5 14.0 0.73837702971\n",
      "10 6.5 14.0 0.739981065581\n",
      "11 6.5 14.0 0.738863826522\n",
      "12 6.5 14.0 0.740111174796\n",
      "13 6.5 14.0 0.739939945276\n",
      "14 6.5 14.0 0.741443207133\n",
      "15 6.5 14.0 0.740993856877\n",
      "3 6.5 14.5 0.716063557883\n",
      "4 6.5 14.5 0.724995538778\n",
      "5 6.5 14.5 0.72814531547\n",
      "6 6.5 14.5 0.732655327388\n",
      "7 6.5 14.5 0.733657556998\n",
      "8 6.5 14.5 0.736731196214\n",
      "9 6.5 14.5 0.73837702971\n",
      "10 6.5 14.5 0.739981065581\n",
      "11 6.5 14.5 0.738863826522\n",
      "12 6.5 14.5 0.740111174796\n",
      "13 6.5 14.5 0.739939945276\n",
      "14 6.5 14.5 0.741443207133\n",
      "15 6.5 14.5 0.740993856877\n",
      "3 6.5 15.0 0.716063557883\n",
      "4 6.5 15.0 0.724995538778\n",
      "5 6.5 15.0 0.72814531547\n",
      "6 6.5 15.0 0.732655327388\n",
      "7 6.5 15.0 0.733657556998\n",
      "8 6.5 15.0 0.736731196214\n",
      "9 6.5 15.0 0.73837702971\n",
      "10 6.5 15.0 0.739981065581\n",
      "11 6.5 15.0 0.738863826522\n",
      "12 6.5 15.0 0.740111174796\n",
      "13 6.5 15.0 0.739939945276\n",
      "14 6.5 15.0 0.741443207133\n",
      "15 6.5 15.0 0.740993856877\n",
      "3 6.5 15.5 0.716063557883\n",
      "4 6.5 15.5 0.724995538778\n",
      "5 6.5 15.5 0.72814531547\n",
      "6 6.5 15.5 0.732655327388\n",
      "7 6.5 15.5 0.733657556998\n",
      "8 6.5 15.5 0.736731196214\n",
      "9 6.5 15.5 0.73837702971\n",
      "10 6.5 15.5 0.739981065581\n",
      "11 6.5 15.5 0.738863826522\n",
      "12 6.5 15.5 0.740111174796\n",
      "13 6.5 15.5 0.739939945276\n",
      "14 6.5 15.5 0.741443207133\n",
      "15 6.5 15.5 0.740993856877\n",
      "3 6.5 16.0 0.716063557883\n",
      "4 6.5 16.0 0.724995538778\n",
      "5 6.5 16.0 0.72814531547\n",
      "6 6.5 16.0 0.732655327388\n",
      "7 6.5 16.0 0.733657556998\n",
      "8 6.5 16.0 0.736731196214\n",
      "9 6.5 16.0 0.73837702971\n",
      "10 6.5 16.0 0.739981065581\n",
      "11 6.5 16.0 0.738863826522\n",
      "12 6.5 16.0 0.740111174796\n",
      "13 6.5 16.0 0.739939945276\n",
      "14 6.5 16.0 0.741443207133\n",
      "15 6.5 16.0 0.740993856877\n",
      "3 6.5 16.5 0.716063557883\n",
      "4 6.5 16.5 0.724995538778\n",
      "5 6.5 16.5 0.72814531547\n",
      "6 6.5 16.5 0.732655327388\n",
      "7 6.5 16.5 0.733657556998\n",
      "8 6.5 16.5 0.736731196214\n",
      "9 6.5 16.5 0.73837702971\n",
      "10 6.5 16.5 0.739981065581\n",
      "11 6.5 16.5 0.738863826522\n",
      "12 6.5 16.5 0.740111174796\n",
      "13 6.5 16.5 0.739939945276\n",
      "14 6.5 16.5 0.741443207133\n",
      "15 6.5 16.5 0.740993856877\n",
      "3 6.5 17.0 0.716063557883\n",
      "4 6.5 17.0 0.724995538778\n",
      "5 6.5 17.0 0.72814531547\n",
      "6 6.5 17.0 0.732655327388\n",
      "7 6.5 17.0 0.733657556998\n",
      "8 6.5 17.0 0.736731196214\n",
      "9 6.5 17.0 0.73837702971\n",
      "10 6.5 17.0 0.739981065581\n",
      "11 6.5 17.0 0.738863826522\n",
      "12 6.5 17.0 0.740111174796\n",
      "13 6.5 17.0 0.739939945276\n",
      "14 6.5 17.0 0.741443207133\n",
      "15 6.5 17.0 0.740993856877\n",
      "3 6.5 17.5 0.716063557883\n",
      "4 6.5 17.5 0.724995538778\n",
      "5 6.5 17.5 0.72814531547\n",
      "6 6.5 17.5 0.732655327388\n",
      "7 6.5 17.5 0.733657556998\n",
      "8 6.5 17.5 0.736731196214\n",
      "9 6.5 17.5 0.73837702971\n",
      "10 6.5 17.5 0.739981065581\n",
      "11 6.5 17.5 0.738863826522\n",
      "12 6.5 17.5 0.740111174796\n",
      "13 6.5 17.5 0.739939945276\n",
      "14 6.5 17.5 0.741443207133\n",
      "15 6.5 17.5 0.740993856877\n",
      "3 7.0 12 0.716063557883\n",
      "4 7.0 12 0.724995538778\n",
      "5 7.0 12 0.72814531547\n",
      "6 7.0 12 0.732655327388\n",
      "7 7.0 12 0.733657556998\n",
      "8 7.0 12 0.736731196214\n",
      "9 7.0 12 0.73837702971\n",
      "10 7.0 12 0.739981065581\n",
      "11 7.0 12 0.738863826522\n",
      "12 7.0 12 0.740111174796\n",
      "13 7.0 12 0.739939945276\n",
      "14 7.0 12 0.741443207133\n",
      "15 7.0 12 0.740993856877\n",
      "3 7.0 12.5 0.716063557883\n",
      "4 7.0 12.5 0.724995538778\n",
      "5 7.0 12.5 0.72814531547\n",
      "6 7.0 12.5 0.732655327388\n",
      "7 7.0 12.5 0.733657556998\n",
      "8 7.0 12.5 0.736731196214\n",
      "9 7.0 12.5 0.73837702971\n",
      "10 7.0 12.5 0.739981065581\n",
      "11 7.0 12.5 0.738863826522\n",
      "12 7.0 12.5 0.740111174796\n",
      "13 7.0 12.5 0.739939945276\n",
      "14 7.0 12.5 0.741443207133\n",
      "15 7.0 12.5 0.740993856877\n",
      "3 7.0 13.0 0.716063557883\n",
      "4 7.0 13.0 0.724995538778\n",
      "5 7.0 13.0 0.72814531547\n",
      "6 7.0 13.0 0.732655327388\n",
      "7 7.0 13.0 0.733657556998\n",
      "8 7.0 13.0 0.736731196214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 7.0 13.0 0.73837702971\n",
      "10 7.0 13.0 0.739981065581\n",
      "11 7.0 13.0 0.738863826522\n",
      "12 7.0 13.0 0.740111174796\n",
      "13 7.0 13.0 0.739939945276\n",
      "14 7.0 13.0 0.741443207133\n",
      "15 7.0 13.0 0.740993856877\n",
      "3 7.0 13.5 0.716063557883\n",
      "4 7.0 13.5 0.724995538778\n",
      "5 7.0 13.5 0.72814531547\n",
      "6 7.0 13.5 0.732655327388\n",
      "7 7.0 13.5 0.733657556998\n",
      "8 7.0 13.5 0.736731196214\n",
      "9 7.0 13.5 0.73837702971\n",
      "10 7.0 13.5 0.739981065581\n",
      "11 7.0 13.5 0.738863826522\n",
      "12 7.0 13.5 0.740111174796\n",
      "13 7.0 13.5 0.739939945276\n",
      "14 7.0 13.5 0.741443207133\n",
      "15 7.0 13.5 0.740993856877\n",
      "3 7.0 14.0 0.716063557883\n",
      "4 7.0 14.0 0.724995538778\n",
      "5 7.0 14.0 0.72814531547\n",
      "6 7.0 14.0 0.732655327388\n",
      "7 7.0 14.0 0.733657556998\n",
      "8 7.0 14.0 0.736731196214\n",
      "9 7.0 14.0 0.73837702971\n",
      "10 7.0 14.0 0.739981065581\n",
      "11 7.0 14.0 0.738863826522\n",
      "12 7.0 14.0 0.740111174796\n",
      "13 7.0 14.0 0.739939945276\n",
      "14 7.0 14.0 0.741443207133\n",
      "15 7.0 14.0 0.740993856877\n",
      "3 7.0 14.5 0.716063557883\n",
      "4 7.0 14.5 0.724995538778\n",
      "5 7.0 14.5 0.72814531547\n",
      "6 7.0 14.5 0.732655327388\n",
      "7 7.0 14.5 0.733657556998\n",
      "8 7.0 14.5 0.736731196214\n",
      "9 7.0 14.5 0.73837702971\n",
      "10 7.0 14.5 0.739981065581\n",
      "11 7.0 14.5 0.738863826522\n",
      "12 7.0 14.5 0.740111174796\n",
      "13 7.0 14.5 0.739939945276\n",
      "14 7.0 14.5 0.741443207133\n",
      "15 7.0 14.5 0.740993856877\n",
      "3 7.0 15.0 0.716063557883\n",
      "4 7.0 15.0 0.724995538778\n",
      "5 7.0 15.0 0.72814531547\n",
      "6 7.0 15.0 0.732655327388\n",
      "7 7.0 15.0 0.733657556998\n",
      "8 7.0 15.0 0.736731196214\n",
      "9 7.0 15.0 0.73837702971\n",
      "10 7.0 15.0 0.739981065581\n",
      "11 7.0 15.0 0.738863826522\n",
      "12 7.0 15.0 0.740111174796\n",
      "13 7.0 15.0 0.739939945276\n",
      "14 7.0 15.0 0.741443207133\n",
      "15 7.0 15.0 0.740993856877\n",
      "3 7.0 15.5 0.716063557883\n",
      "4 7.0 15.5 0.724995538778\n",
      "5 7.0 15.5 0.72814531547\n",
      "6 7.0 15.5 0.732655327388\n",
      "7 7.0 15.5 0.733657556998\n",
      "8 7.0 15.5 0.736731196214\n",
      "9 7.0 15.5 0.73837702971\n",
      "10 7.0 15.5 0.739981065581\n",
      "11 7.0 15.5 0.738863826522\n",
      "12 7.0 15.5 0.740111174796\n",
      "13 7.0 15.5 0.739939945276\n",
      "14 7.0 15.5 0.741443207133\n",
      "15 7.0 15.5 0.740993856877\n",
      "3 7.0 16.0 0.716063557883\n",
      "4 7.0 16.0 0.724995538778\n",
      "5 7.0 16.0 0.72814531547\n",
      "6 7.0 16.0 0.732655327388\n",
      "7 7.0 16.0 0.733657556998\n",
      "8 7.0 16.0 0.736731196214\n",
      "9 7.0 16.0 0.73837702971\n",
      "10 7.0 16.0 0.739981065581\n",
      "11 7.0 16.0 0.738863826522\n",
      "12 7.0 16.0 0.740111174796\n",
      "13 7.0 16.0 0.739939945276\n",
      "14 7.0 16.0 0.741443207133\n",
      "15 7.0 16.0 0.740993856877\n",
      "3 7.0 16.5 0.716063557883\n",
      "4 7.0 16.5 0.724995538778\n",
      "5 7.0 16.5 0.72814531547\n",
      "6 7.0 16.5 0.732655327388\n",
      "7 7.0 16.5 0.733657556998\n",
      "8 7.0 16.5 0.736731196214\n",
      "9 7.0 16.5 0.73837702971\n",
      "10 7.0 16.5 0.739981065581\n",
      "11 7.0 16.5 0.738863826522\n",
      "12 7.0 16.5 0.740111174796\n",
      "13 7.0 16.5 0.739939945276\n",
      "14 7.0 16.5 0.741443207133\n",
      "15 7.0 16.5 0.740993856877\n",
      "3 7.0 17.0 0.716063557883\n",
      "4 7.0 17.0 0.724995538778\n",
      "5 7.0 17.0 0.72814531547\n",
      "6 7.0 17.0 0.732655327388\n",
      "7 7.0 17.0 0.733657556998\n",
      "8 7.0 17.0 0.736731196214\n",
      "9 7.0 17.0 0.73837702971\n",
      "10 7.0 17.0 0.739981065581\n",
      "11 7.0 17.0 0.738863826522\n",
      "12 7.0 17.0 0.740111174796\n",
      "13 7.0 17.0 0.739939945276\n",
      "14 7.0 17.0 0.741443207133\n",
      "15 7.0 17.0 0.740993856877\n",
      "3 7.0 17.5 0.716063557883\n",
      "4 7.0 17.5 0.724995538778\n",
      "5 7.0 17.5 0.72814531547\n",
      "6 7.0 17.5 0.732655327388\n",
      "7 7.0 17.5 0.733657556998\n",
      "8 7.0 17.5 0.736731196214\n",
      "9 7.0 17.5 0.73837702971\n",
      "10 7.0 17.5 0.739981065581\n",
      "11 7.0 17.5 0.738863826522\n",
      "12 7.0 17.5 0.740111174796\n",
      "13 7.0 17.5 0.739939945276\n",
      "14 7.0 17.5 0.741443207133\n",
      "15 7.0 17.5 0.740993856877\n",
      "3 7.5 12 0.716063557883\n",
      "4 7.5 12 0.724995538778\n",
      "5 7.5 12 0.72814531547\n",
      "6 7.5 12 0.732655327388\n",
      "7 7.5 12 0.733657556998\n",
      "8 7.5 12 0.736731196214\n",
      "9 7.5 12 0.73837702971\n",
      "10 7.5 12 0.739981065581\n",
      "11 7.5 12 0.738863826522\n",
      "12 7.5 12 0.740111174796\n",
      "13 7.5 12 0.739939945276\n",
      "14 7.5 12 0.741443207133\n",
      "15 7.5 12 0.740993856877\n",
      "3 7.5 12.5 0.716063557883\n",
      "4 7.5 12.5 0.724995538778\n",
      "5 7.5 12.5 0.72814531547\n",
      "6 7.5 12.5 0.732655327388\n",
      "7 7.5 12.5 0.733657556998\n",
      "8 7.5 12.5 0.736731196214\n",
      "9 7.5 12.5 0.73837702971\n",
      "10 7.5 12.5 0.739981065581\n",
      "11 7.5 12.5 0.738863826522\n",
      "12 7.5 12.5 0.740111174796\n",
      "13 7.5 12.5 0.739939945276\n",
      "14 7.5 12.5 0.741443207133\n",
      "15 7.5 12.5 0.740993856877\n",
      "3 7.5 13.0 0.716063557883\n",
      "4 7.5 13.0 0.724995538778\n",
      "5 7.5 13.0 0.72814531547\n",
      "6 7.5 13.0 0.732655327388\n",
      "7 7.5 13.0 0.733657556998\n",
      "8 7.5 13.0 0.736731196214\n",
      "9 7.5 13.0 0.73837702971\n",
      "10 7.5 13.0 0.739981065581\n",
      "11 7.5 13.0 0.738863826522\n",
      "12 7.5 13.0 0.740111174796\n",
      "13 7.5 13.0 0.739939945276\n",
      "14 7.5 13.0 0.741443207133\n",
      "15 7.5 13.0 0.740993856877\n",
      "3 7.5 13.5 0.716063557883\n",
      "4 7.5 13.5 0.724995538778\n",
      "5 7.5 13.5 0.72814531547\n",
      "6 7.5 13.5 0.732655327388\n",
      "7 7.5 13.5 0.733657556998\n",
      "8 7.5 13.5 0.736731196214\n",
      "9 7.5 13.5 0.73837702971\n",
      "10 7.5 13.5 0.739981065581\n",
      "11 7.5 13.5 0.738863826522\n",
      "12 7.5 13.5 0.740111174796\n",
      "13 7.5 13.5 0.739939945276\n",
      "14 7.5 13.5 0.741443207133\n",
      "15 7.5 13.5 0.740993856877\n",
      "3 7.5 14.0 0.716063557883\n",
      "4 7.5 14.0 0.724995538778\n",
      "5 7.5 14.0 0.72814531547\n",
      "6 7.5 14.0 0.732655327388\n",
      "7 7.5 14.0 0.733657556998\n",
      "8 7.5 14.0 0.736731196214\n",
      "9 7.5 14.0 0.73837702971\n",
      "10 7.5 14.0 0.739981065581\n",
      "11 7.5 14.0 0.738863826522\n",
      "12 7.5 14.0 0.740111174796\n",
      "13 7.5 14.0 0.739939945276\n",
      "14 7.5 14.0 0.741443207133\n",
      "15 7.5 14.0 0.740993856877\n",
      "3 7.5 14.5 0.716063557883\n",
      "4 7.5 14.5 0.724995538778\n",
      "5 7.5 14.5 0.72814531547\n",
      "6 7.5 14.5 0.732655327388\n",
      "7 7.5 14.5 0.733657556998\n",
      "8 7.5 14.5 0.736731196214\n",
      "9 7.5 14.5 0.73837702971\n",
      "10 7.5 14.5 0.739981065581\n",
      "11 7.5 14.5 0.738863826522\n",
      "12 7.5 14.5 0.740111174796\n",
      "13 7.5 14.5 0.739939945276\n",
      "14 7.5 14.5 0.741443207133\n",
      "15 7.5 14.5 0.740993856877\n",
      "3 7.5 15.0 0.716063557883\n",
      "4 7.5 15.0 0.724995538778\n",
      "5 7.5 15.0 0.72814531547\n",
      "6 7.5 15.0 0.732655327388\n",
      "7 7.5 15.0 0.733657556998\n",
      "8 7.5 15.0 0.736731196214\n",
      "9 7.5 15.0 0.73837702971\n",
      "10 7.5 15.0 0.739981065581\n",
      "11 7.5 15.0 0.738863826522\n",
      "12 7.5 15.0 0.740111174796\n",
      "13 7.5 15.0 0.739939945276\n",
      "14 7.5 15.0 0.741443207133\n",
      "15 7.5 15.0 0.740993856877\n",
      "3 7.5 15.5 0.716063557883\n",
      "4 7.5 15.5 0.724995538778\n",
      "5 7.5 15.5 0.72814531547\n",
      "6 7.5 15.5 0.732655327388\n",
      "7 7.5 15.5 0.733657556998\n",
      "8 7.5 15.5 0.736731196214\n",
      "9 7.5 15.5 0.73837702971\n",
      "10 7.5 15.5 0.739981065581\n",
      "11 7.5 15.5 0.738863826522\n",
      "12 7.5 15.5 0.740111174796\n",
      "13 7.5 15.5 0.739939945276\n",
      "14 7.5 15.5 0.741443207133\n",
      "15 7.5 15.5 0.740993856877\n",
      "3 7.5 16.0 0.716063557883\n",
      "4 7.5 16.0 0.724995538778\n",
      "5 7.5 16.0 0.72814531547\n",
      "6 7.5 16.0 0.732655327388\n",
      "7 7.5 16.0 0.733657556998\n",
      "8 7.5 16.0 0.736731196214\n",
      "9 7.5 16.0 0.73837702971\n",
      "10 7.5 16.0 0.739981065581\n",
      "11 7.5 16.0 0.738863826522\n",
      "12 7.5 16.0 0.740111174796\n",
      "13 7.5 16.0 0.739939945276\n",
      "14 7.5 16.0 0.741443207133\n",
      "15 7.5 16.0 0.740993856877\n",
      "3 7.5 16.5 0.716063557883\n",
      "4 7.5 16.5 0.724995538778\n",
      "5 7.5 16.5 0.72814531547\n",
      "6 7.5 16.5 0.732655327388\n",
      "7 7.5 16.5 0.733657556998\n",
      "8 7.5 16.5 0.736731196214\n",
      "9 7.5 16.5 0.73837702971\n",
      "10 7.5 16.5 0.739981065581\n",
      "11 7.5 16.5 0.738863826522\n",
      "12 7.5 16.5 0.740111174796\n",
      "13 7.5 16.5 0.739939945276\n",
      "14 7.5 16.5 0.741443207133\n",
      "15 7.5 16.5 0.740993856877\n",
      "3 7.5 17.0 0.716063557883\n",
      "4 7.5 17.0 0.724995538778\n",
      "5 7.5 17.0 0.72814531547\n",
      "6 7.5 17.0 0.732655327388\n",
      "7 7.5 17.0 0.733657556998\n",
      "8 7.5 17.0 0.736731196214\n",
      "9 7.5 17.0 0.73837702971\n",
      "10 7.5 17.0 0.739981065581\n",
      "11 7.5 17.0 0.738863826522\n",
      "12 7.5 17.0 0.740111174796\n",
      "13 7.5 17.0 0.739939945276\n",
      "14 7.5 17.0 0.741443207133\n",
      "15 7.5 17.0 0.740993856877\n",
      "3 7.5 17.5 0.716063557883\n",
      "4 7.5 17.5 0.724995538778\n",
      "5 7.5 17.5 0.72814531547\n",
      "6 7.5 17.5 0.732655327388\n",
      "7 7.5 17.5 0.733657556998\n",
      "8 7.5 17.5 0.736731196214\n",
      "9 7.5 17.5 0.73837702971\n",
      "10 7.5 17.5 0.739981065581\n",
      "11 7.5 17.5 0.738863826522\n",
      "12 7.5 17.5 0.740111174796\n",
      "13 7.5 17.5 0.739939945276\n",
      "14 7.5 17.5 0.741443207133\n",
      "15 7.5 17.5 0.740993856877\n",
      "3 8.0 12 0.716063557883\n",
      "4 8.0 12 0.724995538778\n",
      "5 8.0 12 0.72814531547\n",
      "6 8.0 12 0.732655327388\n",
      "7 8.0 12 0.733657556998\n",
      "8 8.0 12 0.736731196214\n",
      "9 8.0 12 0.73837702971\n",
      "10 8.0 12 0.739981065581\n",
      "11 8.0 12 0.738863826522\n",
      "12 8.0 12 0.740111174796\n",
      "13 8.0 12 0.739939945276\n",
      "14 8.0 12 0.741443207133\n",
      "15 8.0 12 0.740993856877\n",
      "3 8.0 12.5 0.716063557883\n",
      "4 8.0 12.5 0.724995538778\n",
      "5 8.0 12.5 0.72814531547\n",
      "6 8.0 12.5 0.732655327388\n",
      "7 8.0 12.5 0.733657556998\n",
      "8 8.0 12.5 0.736731196214\n",
      "9 8.0 12.5 0.73837702971\n",
      "10 8.0 12.5 0.739981065581\n",
      "11 8.0 12.5 0.738863826522\n",
      "12 8.0 12.5 0.740111174796\n",
      "13 8.0 12.5 0.739939945276\n",
      "14 8.0 12.5 0.741443207133\n",
      "15 8.0 12.5 0.740993856877\n",
      "3 8.0 13.0 0.716063557883\n",
      "4 8.0 13.0 0.724995538778\n",
      "5 8.0 13.0 0.72814531547\n",
      "6 8.0 13.0 0.732655327388\n",
      "7 8.0 13.0 0.733657556998\n",
      "8 8.0 13.0 0.736731196214\n",
      "9 8.0 13.0 0.73837702971\n",
      "10 8.0 13.0 0.739981065581\n",
      "11 8.0 13.0 0.738863826522\n",
      "12 8.0 13.0 0.740111174796\n",
      "13 8.0 13.0 0.739939945276\n",
      "14 8.0 13.0 0.741443207133\n",
      "15 8.0 13.0 0.740993856877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 8.0 13.5 0.716063557883\n",
      "4 8.0 13.5 0.724995538778\n",
      "5 8.0 13.5 0.72814531547\n",
      "6 8.0 13.5 0.732655327388\n",
      "7 8.0 13.5 0.733657556998\n",
      "8 8.0 13.5 0.736731196214\n",
      "9 8.0 13.5 0.73837702971\n",
      "10 8.0 13.5 0.739981065581\n",
      "11 8.0 13.5 0.738863826522\n",
      "12 8.0 13.5 0.740111174796\n",
      "13 8.0 13.5 0.739939945276\n",
      "14 8.0 13.5 0.741443207133\n",
      "15 8.0 13.5 0.740993856877\n",
      "3 8.0 14.0 0.716063557883\n",
      "4 8.0 14.0 0.724995538778\n",
      "5 8.0 14.0 0.72814531547\n",
      "6 8.0 14.0 0.732655327388\n",
      "7 8.0 14.0 0.733657556998\n",
      "8 8.0 14.0 0.736731196214\n",
      "9 8.0 14.0 0.73837702971\n",
      "10 8.0 14.0 0.739981065581\n",
      "11 8.0 14.0 0.738863826522\n",
      "12 8.0 14.0 0.740111174796\n",
      "13 8.0 14.0 0.739939945276\n",
      "14 8.0 14.0 0.741443207133\n",
      "15 8.0 14.0 0.740993856877\n",
      "3 8.0 14.5 0.716063557883\n",
      "4 8.0 14.5 0.724995538778\n",
      "5 8.0 14.5 0.72814531547\n",
      "6 8.0 14.5 0.732655327388\n",
      "7 8.0 14.5 0.733657556998\n",
      "8 8.0 14.5 0.736731196214\n",
      "9 8.0 14.5 0.73837702971\n",
      "10 8.0 14.5 0.739981065581\n",
      "11 8.0 14.5 0.738863826522\n",
      "12 8.0 14.5 0.740111174796\n",
      "13 8.0 14.5 0.739939945276\n",
      "14 8.0 14.5 0.741443207133\n",
      "15 8.0 14.5 0.740993856877\n",
      "3 8.0 15.0 0.716063557883\n",
      "4 8.0 15.0 0.724995538778\n",
      "5 8.0 15.0 0.72814531547\n",
      "6 8.0 15.0 0.732655327388\n",
      "7 8.0 15.0 0.733657556998\n",
      "8 8.0 15.0 0.736731196214\n",
      "9 8.0 15.0 0.73837702971\n",
      "10 8.0 15.0 0.739981065581\n",
      "11 8.0 15.0 0.738863826522\n",
      "12 8.0 15.0 0.740111174796\n",
      "13 8.0 15.0 0.739939945276\n",
      "14 8.0 15.0 0.741443207133\n",
      "15 8.0 15.0 0.740993856877\n",
      "3 8.0 15.5 0.716063557883\n",
      "4 8.0 15.5 0.724995538778\n",
      "5 8.0 15.5 0.72814531547\n",
      "6 8.0 15.5 0.732655327388\n",
      "7 8.0 15.5 0.733657556998\n",
      "8 8.0 15.5 0.736731196214\n",
      "9 8.0 15.5 0.73837702971\n",
      "10 8.0 15.5 0.739981065581\n",
      "11 8.0 15.5 0.738863826522\n",
      "12 8.0 15.5 0.740111174796\n",
      "13 8.0 15.5 0.739939945276\n",
      "14 8.0 15.5 0.741443207133\n",
      "15 8.0 15.5 0.740993856877\n",
      "3 8.0 16.0 0.716063557883\n",
      "4 8.0 16.0 0.724995538778\n",
      "5 8.0 16.0 0.72814531547\n",
      "6 8.0 16.0 0.732655327388\n",
      "7 8.0 16.0 0.733657556998\n",
      "8 8.0 16.0 0.736731196214\n",
      "9 8.0 16.0 0.73837702971\n",
      "10 8.0 16.0 0.739981065581\n",
      "11 8.0 16.0 0.738863826522\n",
      "12 8.0 16.0 0.740111174796\n",
      "13 8.0 16.0 0.739939945276\n",
      "14 8.0 16.0 0.741443207133\n",
      "15 8.0 16.0 0.740993856877\n",
      "3 8.0 16.5 0.716063557883\n",
      "4 8.0 16.5 0.724995538778\n",
      "5 8.0 16.5 0.72814531547\n",
      "6 8.0 16.5 0.732655327388\n",
      "7 8.0 16.5 0.733657556998\n",
      "8 8.0 16.5 0.736731196214\n",
      "9 8.0 16.5 0.73837702971\n",
      "10 8.0 16.5 0.739981065581\n",
      "11 8.0 16.5 0.738863826522\n",
      "12 8.0 16.5 0.740111174796\n",
      "13 8.0 16.5 0.739939945276\n",
      "14 8.0 16.5 0.741443207133\n",
      "15 8.0 16.5 0.740993856877\n",
      "3 8.0 17.0 0.716063557883\n",
      "4 8.0 17.0 0.724995538778\n",
      "5 8.0 17.0 0.72814531547\n",
      "6 8.0 17.0 0.732655327388\n",
      "7 8.0 17.0 0.733657556998\n",
      "8 8.0 17.0 0.736731196214\n",
      "9 8.0 17.0 0.73837702971\n",
      "10 8.0 17.0 0.739981065581\n",
      "11 8.0 17.0 0.738863826522\n",
      "12 8.0 17.0 0.740111174796\n",
      "13 8.0 17.0 0.739939945276\n",
      "14 8.0 17.0 0.741443207133\n",
      "15 8.0 17.0 0.740993856877\n",
      "3 8.0 17.5 0.716063557883\n",
      "4 8.0 17.5 0.724995538778\n",
      "5 8.0 17.5 0.72814531547\n",
      "6 8.0 17.5 0.732655327388\n",
      "7 8.0 17.5 0.733657556998\n",
      "8 8.0 17.5 0.736731196214\n",
      "9 8.0 17.5 0.73837702971\n",
      "10 8.0 17.5 0.739981065581\n",
      "11 8.0 17.5 0.738863826522\n",
      "12 8.0 17.5 0.740111174796\n",
      "13 8.0 17.5 0.739939945276\n",
      "14 8.0 17.5 0.741443207133\n",
      "15 8.0 17.5 0.740993856877\n",
      "3 8.5 12 0.716063557883\n",
      "4 8.5 12 0.724995538778\n",
      "5 8.5 12 0.72814531547\n",
      "6 8.5 12 0.732655327388\n",
      "7 8.5 12 0.733657556998\n",
      "8 8.5 12 0.736731196214\n",
      "9 8.5 12 0.73837702971\n",
      "10 8.5 12 0.739981065581\n",
      "11 8.5 12 0.738863826522\n",
      "12 8.5 12 0.740111174796\n",
      "13 8.5 12 0.739939945276\n",
      "14 8.5 12 0.741443207133\n",
      "15 8.5 12 0.740993856877\n",
      "3 8.5 12.5 0.716063557883\n",
      "4 8.5 12.5 0.724995538778\n",
      "5 8.5 12.5 0.72814531547\n",
      "6 8.5 12.5 0.732655327388\n",
      "7 8.5 12.5 0.733657556998\n",
      "8 8.5 12.5 0.736731196214\n",
      "9 8.5 12.5 0.73837702971\n",
      "10 8.5 12.5 0.739981065581\n",
      "11 8.5 12.5 0.738863826522\n",
      "12 8.5 12.5 0.740111174796\n",
      "13 8.5 12.5 0.739939945276\n",
      "14 8.5 12.5 0.741443207133\n",
      "15 8.5 12.5 0.740993856877\n",
      "3 8.5 13.0 0.716063557883\n",
      "4 8.5 13.0 0.724995538778\n",
      "5 8.5 13.0 0.72814531547\n",
      "6 8.5 13.0 0.732655327388\n",
      "7 8.5 13.0 0.733657556998\n",
      "8 8.5 13.0 0.736731196214\n",
      "9 8.5 13.0 0.73837702971\n",
      "10 8.5 13.0 0.739981065581\n",
      "11 8.5 13.0 0.738863826522\n",
      "12 8.5 13.0 0.740111174796\n",
      "13 8.5 13.0 0.739939945276\n",
      "14 8.5 13.0 0.741443207133\n",
      "15 8.5 13.0 0.740993856877\n",
      "3 8.5 13.5 0.716063557883\n",
      "4 8.5 13.5 0.724995538778\n",
      "5 8.5 13.5 0.72814531547\n",
      "6 8.5 13.5 0.732655327388\n",
      "7 8.5 13.5 0.733657556998\n",
      "8 8.5 13.5 0.736731196214\n",
      "9 8.5 13.5 0.73837702971\n",
      "10 8.5 13.5 0.739981065581\n",
      "11 8.5 13.5 0.738863826522\n",
      "12 8.5 13.5 0.740111174796\n",
      "13 8.5 13.5 0.739939945276\n",
      "14 8.5 13.5 0.741443207133\n",
      "15 8.5 13.5 0.740993856877\n",
      "3 8.5 14.0 0.716063557883\n",
      "4 8.5 14.0 0.724995538778\n",
      "5 8.5 14.0 0.72814531547\n",
      "6 8.5 14.0 0.732655327388\n",
      "7 8.5 14.0 0.733657556998\n",
      "8 8.5 14.0 0.736731196214\n",
      "9 8.5 14.0 0.73837702971\n",
      "10 8.5 14.0 0.739981065581\n",
      "11 8.5 14.0 0.738863826522\n",
      "12 8.5 14.0 0.740111174796\n",
      "13 8.5 14.0 0.739939945276\n",
      "14 8.5 14.0 0.741443207133\n",
      "15 8.5 14.0 0.740993856877\n",
      "3 8.5 14.5 0.716063557883\n",
      "4 8.5 14.5 0.724995538778\n",
      "5 8.5 14.5 0.72814531547\n",
      "6 8.5 14.5 0.732655327388\n",
      "7 8.5 14.5 0.733657556998\n",
      "8 8.5 14.5 0.736731196214\n",
      "9 8.5 14.5 0.73837702971\n",
      "10 8.5 14.5 0.739981065581\n",
      "11 8.5 14.5 0.738863826522\n",
      "12 8.5 14.5 0.740111174796\n",
      "13 8.5 14.5 0.739939945276\n",
      "14 8.5 14.5 0.741443207133\n",
      "15 8.5 14.5 0.740993856877\n",
      "3 8.5 15.0 0.716063557883\n",
      "4 8.5 15.0 0.724995538778\n",
      "5 8.5 15.0 0.72814531547\n",
      "6 8.5 15.0 0.732655327388\n",
      "7 8.5 15.0 0.733657556998\n",
      "8 8.5 15.0 0.736731196214\n",
      "9 8.5 15.0 0.73837702971\n",
      "10 8.5 15.0 0.739981065581\n",
      "11 8.5 15.0 0.738863826522\n",
      "12 8.5 15.0 0.740111174796\n",
      "13 8.5 15.0 0.739939945276\n",
      "14 8.5 15.0 0.741443207133\n",
      "15 8.5 15.0 0.740993856877\n",
      "3 8.5 15.5 0.716063557883\n",
      "4 8.5 15.5 0.724995538778\n",
      "5 8.5 15.5 0.72814531547\n",
      "6 8.5 15.5 0.732655327388\n",
      "7 8.5 15.5 0.733657556998\n",
      "8 8.5 15.5 0.736731196214\n",
      "9 8.5 15.5 0.73837702971\n",
      "10 8.5 15.5 0.739981065581\n",
      "11 8.5 15.5 0.738863826522\n",
      "12 8.5 15.5 0.740111174796\n",
      "13 8.5 15.5 0.739939945276\n",
      "14 8.5 15.5 0.741443207133\n",
      "15 8.5 15.5 0.740993856877\n",
      "3 8.5 16.0 0.716063557883\n",
      "4 8.5 16.0 0.724995538778\n",
      "5 8.5 16.0 0.72814531547\n",
      "6 8.5 16.0 0.732655327388\n",
      "7 8.5 16.0 0.733657556998\n",
      "8 8.5 16.0 0.736731196214\n",
      "9 8.5 16.0 0.73837702971\n",
      "10 8.5 16.0 0.739981065581\n",
      "11 8.5 16.0 0.738863826522\n",
      "12 8.5 16.0 0.740111174796\n",
      "13 8.5 16.0 0.739939945276\n",
      "14 8.5 16.0 0.741443207133\n",
      "15 8.5 16.0 0.740993856877\n",
      "3 8.5 16.5 0.716063557883\n",
      "4 8.5 16.5 0.724995538778\n",
      "5 8.5 16.5 0.72814531547\n",
      "6 8.5 16.5 0.732655327388\n",
      "7 8.5 16.5 0.733657556998\n",
      "8 8.5 16.5 0.736731196214\n",
      "9 8.5 16.5 0.73837702971\n",
      "10 8.5 16.5 0.739981065581\n",
      "11 8.5 16.5 0.738863826522\n",
      "12 8.5 16.5 0.740111174796\n",
      "13 8.5 16.5 0.739939945276\n",
      "14 8.5 16.5 0.741443207133\n",
      "15 8.5 16.5 0.740993856877\n",
      "3 8.5 17.0 0.716063557883\n",
      "4 8.5 17.0 0.724995538778\n",
      "5 8.5 17.0 0.72814531547\n",
      "6 8.5 17.0 0.732655327388\n",
      "7 8.5 17.0 0.733657556998\n",
      "8 8.5 17.0 0.736731196214\n",
      "9 8.5 17.0 0.73837702971\n",
      "10 8.5 17.0 0.739981065581\n",
      "11 8.5 17.0 0.738863826522\n",
      "12 8.5 17.0 0.740111174796\n",
      "13 8.5 17.0 0.739939945276\n",
      "14 8.5 17.0 0.741443207133\n",
      "15 8.5 17.0 0.740993856877\n",
      "3 8.5 17.5 0.716063557883\n",
      "4 8.5 17.5 0.724995538778\n",
      "5 8.5 17.5 0.72814531547\n",
      "6 8.5 17.5 0.732655327388\n",
      "7 8.5 17.5 0.733657556998\n",
      "8 8.5 17.5 0.736731196214\n",
      "9 8.5 17.5 0.73837702971\n",
      "10 8.5 17.5 0.739981065581\n",
      "11 8.5 17.5 0.738863826522\n",
      "12 8.5 17.5 0.740111174796\n",
      "13 8.5 17.5 0.739939945276\n",
      "14 8.5 17.5 0.741443207133\n",
      "15 8.5 17.5 0.740993856877\n",
      "3 9.0 12 0.716063557883\n",
      "4 9.0 12 0.724995538778\n",
      "5 9.0 12 0.72814531547\n",
      "6 9.0 12 0.732655327388\n",
      "7 9.0 12 0.733657556998\n",
      "8 9.0 12 0.736731196214\n",
      "9 9.0 12 0.73837702971\n",
      "10 9.0 12 0.739981065581\n",
      "11 9.0 12 0.738863826522\n",
      "12 9.0 12 0.740111174796\n",
      "13 9.0 12 0.739939945276\n",
      "14 9.0 12 0.741443207133\n",
      "15 9.0 12 0.740993856877\n",
      "3 9.0 12.5 0.716063557883\n",
      "4 9.0 12.5 0.724995538778\n",
      "5 9.0 12.5 0.72814531547\n",
      "6 9.0 12.5 0.732655327388\n",
      "7 9.0 12.5 0.733657556998\n",
      "8 9.0 12.5 0.736731196214\n",
      "9 9.0 12.5 0.73837702971\n",
      "10 9.0 12.5 0.739981065581\n",
      "11 9.0 12.5 0.738863826522\n",
      "12 9.0 12.5 0.740111174796\n",
      "13 9.0 12.5 0.739939945276\n",
      "14 9.0 12.5 0.741443207133\n",
      "15 9.0 12.5 0.740993856877\n",
      "3 9.0 13.0 0.716063557883\n",
      "4 9.0 13.0 0.724995538778\n",
      "5 9.0 13.0 0.72814531547\n",
      "6 9.0 13.0 0.732655327388\n",
      "7 9.0 13.0 0.733657556998\n",
      "8 9.0 13.0 0.736731196214\n",
      "9 9.0 13.0 0.73837702971\n",
      "10 9.0 13.0 0.739981065581\n",
      "11 9.0 13.0 0.738863826522\n",
      "12 9.0 13.0 0.740111174796\n",
      "13 9.0 13.0 0.739939945276\n",
      "14 9.0 13.0 0.741443207133\n",
      "15 9.0 13.0 0.740993856877\n",
      "3 9.0 13.5 0.716063557883\n",
      "4 9.0 13.5 0.724995538778\n",
      "5 9.0 13.5 0.72814531547\n",
      "6 9.0 13.5 0.732655327388\n",
      "7 9.0 13.5 0.733657556998\n",
      "8 9.0 13.5 0.736731196214\n",
      "9 9.0 13.5 0.73837702971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 9.0 13.5 0.739981065581\n",
      "11 9.0 13.5 0.738863826522\n",
      "12 9.0 13.5 0.740111174796\n",
      "13 9.0 13.5 0.739939945276\n",
      "14 9.0 13.5 0.741443207133\n",
      "15 9.0 13.5 0.740993856877\n",
      "3 9.0 14.0 0.716063557883\n",
      "4 9.0 14.0 0.724995538778\n",
      "5 9.0 14.0 0.72814531547\n",
      "6 9.0 14.0 0.732655327388\n",
      "7 9.0 14.0 0.733657556998\n",
      "8 9.0 14.0 0.736731196214\n",
      "9 9.0 14.0 0.73837702971\n",
      "10 9.0 14.0 0.739981065581\n",
      "11 9.0 14.0 0.738863826522\n",
      "12 9.0 14.0 0.740111174796\n",
      "13 9.0 14.0 0.739939945276\n",
      "14 9.0 14.0 0.741443207133\n",
      "15 9.0 14.0 0.740993856877\n",
      "3 9.0 14.5 0.716063557883\n",
      "4 9.0 14.5 0.724995538778\n",
      "5 9.0 14.5 0.72814531547\n",
      "6 9.0 14.5 0.732655327388\n",
      "7 9.0 14.5 0.733657556998\n",
      "8 9.0 14.5 0.736731196214\n",
      "9 9.0 14.5 0.73837702971\n",
      "10 9.0 14.5 0.739981065581\n",
      "11 9.0 14.5 0.738863826522\n",
      "12 9.0 14.5 0.740111174796\n",
      "13 9.0 14.5 0.739939945276\n",
      "14 9.0 14.5 0.741443207133\n",
      "15 9.0 14.5 0.740993856877\n",
      "3 9.0 15.0 0.716063557883\n",
      "4 9.0 15.0 0.724995538778\n",
      "5 9.0 15.0 0.72814531547\n",
      "6 9.0 15.0 0.732655327388\n",
      "7 9.0 15.0 0.733657556998\n",
      "8 9.0 15.0 0.736731196214\n",
      "9 9.0 15.0 0.73837702971\n",
      "10 9.0 15.0 0.739981065581\n",
      "11 9.0 15.0 0.738863826522\n",
      "12 9.0 15.0 0.740111174796\n",
      "13 9.0 15.0 0.739939945276\n",
      "14 9.0 15.0 0.741443207133\n",
      "15 9.0 15.0 0.740993856877\n",
      "3 9.0 15.5 0.716063557883\n",
      "4 9.0 15.5 0.724995538778\n",
      "5 9.0 15.5 0.72814531547\n",
      "6 9.0 15.5 0.732655327388\n",
      "7 9.0 15.5 0.733657556998\n",
      "8 9.0 15.5 0.736731196214\n",
      "9 9.0 15.5 0.73837702971\n",
      "10 9.0 15.5 0.739981065581\n",
      "11 9.0 15.5 0.738863826522\n",
      "12 9.0 15.5 0.740111174796\n",
      "13 9.0 15.5 0.739939945276\n",
      "14 9.0 15.5 0.741443207133\n",
      "15 9.0 15.5 0.740993856877\n",
      "3 9.0 16.0 0.716063557883\n",
      "4 9.0 16.0 0.724995538778\n",
      "5 9.0 16.0 0.72814531547\n",
      "6 9.0 16.0 0.732655327388\n",
      "7 9.0 16.0 0.733657556998\n",
      "8 9.0 16.0 0.736731196214\n",
      "9 9.0 16.0 0.73837702971\n",
      "10 9.0 16.0 0.739981065581\n",
      "11 9.0 16.0 0.738863826522\n",
      "12 9.0 16.0 0.740111174796\n",
      "13 9.0 16.0 0.739939945276\n",
      "14 9.0 16.0 0.741443207133\n",
      "15 9.0 16.0 0.740993856877\n",
      "3 9.0 16.5 0.716063557883\n",
      "4 9.0 16.5 0.724995538778\n",
      "5 9.0 16.5 0.72814531547\n",
      "6 9.0 16.5 0.732655327388\n",
      "7 9.0 16.5 0.733657556998\n",
      "8 9.0 16.5 0.736731196214\n",
      "9 9.0 16.5 0.73837702971\n",
      "10 9.0 16.5 0.739981065581\n",
      "11 9.0 16.5 0.738863826522\n",
      "12 9.0 16.5 0.740111174796\n",
      "13 9.0 16.5 0.739939945276\n",
      "14 9.0 16.5 0.741443207133\n",
      "15 9.0 16.5 0.740993856877\n",
      "3 9.0 17.0 0.716063557883\n",
      "4 9.0 17.0 0.724995538778\n",
      "5 9.0 17.0 0.72814531547\n",
      "6 9.0 17.0 0.732655327388\n",
      "7 9.0 17.0 0.733657556998\n",
      "8 9.0 17.0 0.736731196214\n",
      "9 9.0 17.0 0.73837702971\n",
      "10 9.0 17.0 0.739981065581\n",
      "11 9.0 17.0 0.738863826522\n",
      "12 9.0 17.0 0.740111174796\n",
      "13 9.0 17.0 0.739939945276\n",
      "14 9.0 17.0 0.741443207133\n",
      "15 9.0 17.0 0.740993856877\n",
      "3 9.0 17.5 0.716063557883\n",
      "4 9.0 17.5 0.724995538778\n",
      "5 9.0 17.5 0.72814531547\n",
      "6 9.0 17.5 0.732655327388\n",
      "7 9.0 17.5 0.733657556998\n",
      "8 9.0 17.5 0.736731196214\n",
      "9 9.0 17.5 0.73837702971\n",
      "10 9.0 17.5 0.739981065581\n",
      "11 9.0 17.5 0.738863826522\n",
      "12 9.0 17.5 0.740111174796\n",
      "13 9.0 17.5 0.739939945276\n",
      "14 9.0 17.5 0.741443207133\n",
      "15 9.0 17.5 0.740993856877\n",
      "3 9.5 12 0.716063557883\n",
      "4 9.5 12 0.724995538778\n",
      "5 9.5 12 0.72814531547\n",
      "6 9.5 12 0.732655327388\n",
      "7 9.5 12 0.733657556998\n",
      "8 9.5 12 0.736731196214\n",
      "9 9.5 12 0.73837702971\n",
      "10 9.5 12 0.739981065581\n",
      "11 9.5 12 0.738863826522\n",
      "12 9.5 12 0.740111174796\n",
      "13 9.5 12 0.739939945276\n",
      "14 9.5 12 0.741443207133\n",
      "15 9.5 12 0.740993856877\n",
      "3 9.5 12.5 0.716063557883\n",
      "4 9.5 12.5 0.724995538778\n",
      "5 9.5 12.5 0.72814531547\n",
      "6 9.5 12.5 0.732655327388\n",
      "7 9.5 12.5 0.733657556998\n",
      "8 9.5 12.5 0.736731196214\n",
      "9 9.5 12.5 0.73837702971\n",
      "10 9.5 12.5 0.739981065581\n",
      "11 9.5 12.5 0.738863826522\n",
      "12 9.5 12.5 0.740111174796\n",
      "13 9.5 12.5 0.739939945276\n",
      "14 9.5 12.5 0.741443207133\n",
      "15 9.5 12.5 0.740993856877\n",
      "3 9.5 13.0 0.716063557883\n",
      "4 9.5 13.0 0.724995538778\n",
      "5 9.5 13.0 0.72814531547\n",
      "6 9.5 13.0 0.732655327388\n",
      "7 9.5 13.0 0.733657556998\n",
      "8 9.5 13.0 0.736731196214\n",
      "9 9.5 13.0 0.73837702971\n",
      "10 9.5 13.0 0.739981065581\n",
      "11 9.5 13.0 0.738863826522\n",
      "12 9.5 13.0 0.740111174796\n",
      "13 9.5 13.0 0.739939945276\n",
      "14 9.5 13.0 0.741443207133\n",
      "15 9.5 13.0 0.740993856877\n",
      "3 9.5 13.5 0.716063557883\n",
      "4 9.5 13.5 0.724995538778\n",
      "5 9.5 13.5 0.72814531547\n",
      "6 9.5 13.5 0.732655327388\n",
      "7 9.5 13.5 0.733657556998\n",
      "8 9.5 13.5 0.736731196214\n",
      "9 9.5 13.5 0.73837702971\n",
      "10 9.5 13.5 0.739981065581\n",
      "11 9.5 13.5 0.738863826522\n",
      "12 9.5 13.5 0.740111174796\n",
      "13 9.5 13.5 0.739939945276\n",
      "14 9.5 13.5 0.741443207133\n",
      "15 9.5 13.5 0.740993856877\n",
      "3 9.5 14.0 0.716063557883\n",
      "4 9.5 14.0 0.724995538778\n",
      "5 9.5 14.0 0.72814531547\n",
      "6 9.5 14.0 0.732655327388\n",
      "7 9.5 14.0 0.733657556998\n",
      "8 9.5 14.0 0.736731196214\n",
      "9 9.5 14.0 0.73837702971\n",
      "10 9.5 14.0 0.739981065581\n",
      "11 9.5 14.0 0.738863826522\n",
      "12 9.5 14.0 0.740111174796\n",
      "13 9.5 14.0 0.739939945276\n",
      "14 9.5 14.0 0.741443207133\n",
      "15 9.5 14.0 0.740993856877\n",
      "3 9.5 14.5 0.716063557883\n",
      "4 9.5 14.5 0.724995538778\n",
      "5 9.5 14.5 0.72814531547\n",
      "6 9.5 14.5 0.732655327388\n",
      "7 9.5 14.5 0.733657556998\n",
      "8 9.5 14.5 0.736731196214\n",
      "9 9.5 14.5 0.73837702971\n",
      "10 9.5 14.5 0.739981065581\n",
      "11 9.5 14.5 0.738863826522\n",
      "12 9.5 14.5 0.740111174796\n",
      "13 9.5 14.5 0.739939945276\n",
      "14 9.5 14.5 0.741443207133\n",
      "15 9.5 14.5 0.740993856877\n",
      "3 9.5 15.0 0.716063557883\n",
      "4 9.5 15.0 0.724995538778\n",
      "5 9.5 15.0 0.72814531547\n",
      "6 9.5 15.0 0.732655327388\n",
      "7 9.5 15.0 0.733657556998\n",
      "8 9.5 15.0 0.736731196214\n",
      "9 9.5 15.0 0.73837702971\n",
      "10 9.5 15.0 0.739981065581\n",
      "11 9.5 15.0 0.738863826522\n",
      "12 9.5 15.0 0.740111174796\n",
      "13 9.5 15.0 0.739939945276\n",
      "14 9.5 15.0 0.741443207133\n",
      "15 9.5 15.0 0.740993856877\n",
      "3 9.5 15.5 0.716063557883\n",
      "4 9.5 15.5 0.724995538778\n",
      "5 9.5 15.5 0.72814531547\n",
      "6 9.5 15.5 0.732655327388\n",
      "7 9.5 15.5 0.733657556998\n",
      "8 9.5 15.5 0.736731196214\n",
      "9 9.5 15.5 0.73837702971\n",
      "10 9.5 15.5 0.739981065581\n",
      "11 9.5 15.5 0.738863826522\n",
      "12 9.5 15.5 0.740111174796\n",
      "13 9.5 15.5 0.739939945276\n",
      "14 9.5 15.5 0.741443207133\n",
      "15 9.5 15.5 0.740993856877\n",
      "3 9.5 16.0 0.716063557883\n",
      "4 9.5 16.0 0.724995538778\n",
      "5 9.5 16.0 0.72814531547\n",
      "6 9.5 16.0 0.732655327388\n",
      "7 9.5 16.0 0.733657556998\n",
      "8 9.5 16.0 0.736731196214\n",
      "9 9.5 16.0 0.73837702971\n",
      "10 9.5 16.0 0.739981065581\n",
      "11 9.5 16.0 0.738863826522\n",
      "12 9.5 16.0 0.740111174796\n",
      "13 9.5 16.0 0.739939945276\n",
      "14 9.5 16.0 0.741443207133\n",
      "15 9.5 16.0 0.740993856877\n",
      "3 9.5 16.5 0.716063557883\n",
      "4 9.5 16.5 0.724995538778\n",
      "5 9.5 16.5 0.72814531547\n",
      "6 9.5 16.5 0.732655327388\n",
      "7 9.5 16.5 0.733657556998\n",
      "8 9.5 16.5 0.736731196214\n",
      "9 9.5 16.5 0.73837702971\n",
      "10 9.5 16.5 0.739981065581\n",
      "11 9.5 16.5 0.738863826522\n",
      "12 9.5 16.5 0.740111174796\n",
      "13 9.5 16.5 0.739939945276\n",
      "14 9.5 16.5 0.741443207133\n",
      "15 9.5 16.5 0.740993856877\n",
      "3 9.5 17.0 0.716063557883\n",
      "4 9.5 17.0 0.724995538778\n",
      "5 9.5 17.0 0.72814531547\n",
      "6 9.5 17.0 0.732655327388\n",
      "7 9.5 17.0 0.733657556998\n",
      "8 9.5 17.0 0.736731196214\n",
      "9 9.5 17.0 0.73837702971\n",
      "10 9.5 17.0 0.739981065581\n",
      "11 9.5 17.0 0.738863826522\n",
      "12 9.5 17.0 0.740111174796\n",
      "13 9.5 17.0 0.739939945276\n",
      "14 9.5 17.0 0.741443207133\n",
      "15 9.5 17.0 0.740993856877\n",
      "3 9.5 17.5 0.716063557883\n",
      "4 9.5 17.5 0.724995538778\n",
      "5 9.5 17.5 0.72814531547\n",
      "6 9.5 17.5 0.732655327388\n",
      "7 9.5 17.5 0.733657556998\n",
      "8 9.5 17.5 0.736731196214\n",
      "9 9.5 17.5 0.73837702971\n",
      "10 9.5 17.5 0.739981065581\n",
      "11 9.5 17.5 0.738863826522\n",
      "12 9.5 17.5 0.740111174796\n",
      "13 9.5 17.5 0.739939945276\n",
      "14 9.5 17.5 0.741443207133\n",
      "15 9.5 17.5 0.740993856877\n",
      "3 10.0 12 0.716063557883\n",
      "4 10.0 12 0.724995538778\n",
      "5 10.0 12 0.72814531547\n",
      "6 10.0 12 0.732655327388\n",
      "7 10.0 12 0.733657556998\n",
      "8 10.0 12 0.736731196214\n",
      "9 10.0 12 0.73837702971\n",
      "10 10.0 12 0.739981065581\n",
      "11 10.0 12 0.738863826522\n",
      "12 10.0 12 0.740111174796\n",
      "13 10.0 12 0.739939945276\n",
      "14 10.0 12 0.741443207133\n",
      "15 10.0 12 0.740993856877\n",
      "3 10.0 12.5 0.716063557883\n",
      "4 10.0 12.5 0.724995538778\n",
      "5 10.0 12.5 0.72814531547\n",
      "6 10.0 12.5 0.732655327388\n",
      "7 10.0 12.5 0.733657556998\n",
      "8 10.0 12.5 0.736731196214\n",
      "9 10.0 12.5 0.73837702971\n",
      "10 10.0 12.5 0.739981065581\n",
      "11 10.0 12.5 0.738863826522\n",
      "12 10.0 12.5 0.740111174796\n",
      "13 10.0 12.5 0.739939945276\n",
      "14 10.0 12.5 0.741443207133\n",
      "15 10.0 12.5 0.740993856877\n",
      "3 10.0 13.0 0.716063557883\n",
      "4 10.0 13.0 0.724995538778\n",
      "5 10.0 13.0 0.72814531547\n",
      "6 10.0 13.0 0.732655327388\n",
      "7 10.0 13.0 0.733657556998\n",
      "8 10.0 13.0 0.736731196214\n",
      "9 10.0 13.0 0.73837702971\n",
      "10 10.0 13.0 0.739981065581\n",
      "11 10.0 13.0 0.738863826522\n",
      "12 10.0 13.0 0.740111174796\n",
      "13 10.0 13.0 0.739939945276\n",
      "14 10.0 13.0 0.741443207133\n",
      "15 10.0 13.0 0.740993856877\n",
      "3 10.0 13.5 0.716063557883\n",
      "4 10.0 13.5 0.724995538778\n",
      "5 10.0 13.5 0.72814531547\n",
      "6 10.0 13.5 0.732655327388\n",
      "7 10.0 13.5 0.733657556998\n",
      "8 10.0 13.5 0.736731196214\n",
      "9 10.0 13.5 0.73837702971\n",
      "10 10.0 13.5 0.739981065581\n",
      "11 10.0 13.5 0.738863826522\n",
      "12 10.0 13.5 0.740111174796\n",
      "13 10.0 13.5 0.739939945276\n",
      "14 10.0 13.5 0.741443207133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 10.0 13.5 0.740993856877\n",
      "3 10.0 14.0 0.716063557883\n",
      "4 10.0 14.0 0.724995538778\n",
      "5 10.0 14.0 0.72814531547\n",
      "6 10.0 14.0 0.732655327388\n",
      "7 10.0 14.0 0.733657556998\n",
      "8 10.0 14.0 0.736731196214\n",
      "9 10.0 14.0 0.73837702971\n",
      "10 10.0 14.0 0.739981065581\n",
      "11 10.0 14.0 0.738863826522\n",
      "12 10.0 14.0 0.740111174796\n",
      "13 10.0 14.0 0.739939945276\n",
      "14 10.0 14.0 0.741443207133\n",
      "15 10.0 14.0 0.740993856877\n",
      "3 10.0 14.5 0.716063557883\n",
      "4 10.0 14.5 0.724995538778\n",
      "5 10.0 14.5 0.72814531547\n",
      "6 10.0 14.5 0.732655327388\n",
      "7 10.0 14.5 0.733657556998\n",
      "8 10.0 14.5 0.736731196214\n",
      "9 10.0 14.5 0.73837702971\n",
      "10 10.0 14.5 0.739981065581\n",
      "11 10.0 14.5 0.738863826522\n",
      "12 10.0 14.5 0.740111174796\n",
      "13 10.0 14.5 0.739939945276\n",
      "14 10.0 14.5 0.741443207133\n",
      "15 10.0 14.5 0.740993856877\n",
      "3 10.0 15.0 0.716063557883\n",
      "4 10.0 15.0 0.724995538778\n",
      "5 10.0 15.0 0.72814531547\n",
      "6 10.0 15.0 0.732655327388\n",
      "7 10.0 15.0 0.733657556998\n",
      "8 10.0 15.0 0.736731196214\n",
      "9 10.0 15.0 0.73837702971\n",
      "10 10.0 15.0 0.739981065581\n",
      "11 10.0 15.0 0.738863826522\n",
      "12 10.0 15.0 0.740111174796\n",
      "13 10.0 15.0 0.739939945276\n",
      "14 10.0 15.0 0.741443207133\n",
      "15 10.0 15.0 0.740993856877\n",
      "3 10.0 15.5 0.716063557883\n",
      "4 10.0 15.5 0.724995538778\n",
      "5 10.0 15.5 0.72814531547\n",
      "6 10.0 15.5 0.732655327388\n",
      "7 10.0 15.5 0.733657556998\n",
      "8 10.0 15.5 0.736731196214\n",
      "9 10.0 15.5 0.73837702971\n",
      "10 10.0 15.5 0.739981065581\n",
      "11 10.0 15.5 0.738863826522\n",
      "12 10.0 15.5 0.740111174796\n",
      "13 10.0 15.5 0.739939945276\n",
      "14 10.0 15.5 0.741443207133\n",
      "15 10.0 15.5 0.740993856877\n",
      "3 10.0 16.0 0.716063557883\n",
      "4 10.0 16.0 0.724995538778\n",
      "5 10.0 16.0 0.72814531547\n",
      "6 10.0 16.0 0.732655327388\n",
      "7 10.0 16.0 0.733657556998\n",
      "8 10.0 16.0 0.736731196214\n",
      "9 10.0 16.0 0.73837702971\n",
      "10 10.0 16.0 0.739981065581\n",
      "11 10.0 16.0 0.738863826522\n",
      "12 10.0 16.0 0.740111174796\n",
      "13 10.0 16.0 0.739939945276\n",
      "14 10.0 16.0 0.741443207133\n",
      "15 10.0 16.0 0.740993856877\n",
      "3 10.0 16.5 0.716063557883\n",
      "4 10.0 16.5 0.724995538778\n",
      "5 10.0 16.5 0.72814531547\n",
      "6 10.0 16.5 0.732655327388\n",
      "7 10.0 16.5 0.733657556998\n",
      "8 10.0 16.5 0.736731196214\n",
      "9 10.0 16.5 0.73837702971\n",
      "10 10.0 16.5 0.739981065581\n",
      "11 10.0 16.5 0.738863826522\n",
      "12 10.0 16.5 0.740111174796\n",
      "13 10.0 16.5 0.739939945276\n",
      "14 10.0 16.5 0.741443207133\n",
      "15 10.0 16.5 0.740993856877\n",
      "3 10.0 17.0 0.716063557883\n",
      "4 10.0 17.0 0.724995538778\n",
      "5 10.0 17.0 0.72814531547\n",
      "6 10.0 17.0 0.732655327388\n",
      "7 10.0 17.0 0.733657556998\n",
      "8 10.0 17.0 0.736731196214\n",
      "9 10.0 17.0 0.73837702971\n",
      "10 10.0 17.0 0.739981065581\n",
      "11 10.0 17.0 0.738863826522\n",
      "12 10.0 17.0 0.740111174796\n",
      "13 10.0 17.0 0.739939945276\n",
      "14 10.0 17.0 0.741443207133\n",
      "15 10.0 17.0 0.740993856877\n",
      "3 10.0 17.5 0.716063557883\n",
      "4 10.0 17.5 0.724995538778\n",
      "5 10.0 17.5 0.72814531547\n",
      "6 10.0 17.5 0.732655327388\n",
      "7 10.0 17.5 0.733657556998\n",
      "8 10.0 17.5 0.736731196214\n",
      "9 10.0 17.5 0.73837702971\n",
      "10 10.0 17.5 0.739981065581\n",
      "11 10.0 17.5 0.738863826522\n",
      "12 10.0 17.5 0.740111174796\n",
      "13 10.0 17.5 0.739939945276\n",
      "14 10.0 17.5 0.741443207133\n",
      "15 10.0 17.5 0.740993856877\n",
      "3 10.5 12 0.716063557883\n",
      "4 10.5 12 0.724995538778\n",
      "5 10.5 12 0.72814531547\n",
      "6 10.5 12 0.732655327388\n",
      "7 10.5 12 0.733657556998\n",
      "8 10.5 12 0.736731196214\n",
      "9 10.5 12 0.73837702971\n",
      "10 10.5 12 0.739981065581\n",
      "11 10.5 12 0.738863826522\n",
      "12 10.5 12 0.740111174796\n",
      "13 10.5 12 0.739939945276\n",
      "14 10.5 12 0.741443207133\n",
      "15 10.5 12 0.740993856877\n",
      "3 10.5 12.5 0.716063557883\n",
      "4 10.5 12.5 0.724995538778\n",
      "5 10.5 12.5 0.72814531547\n",
      "6 10.5 12.5 0.732655327388\n",
      "7 10.5 12.5 0.733657556998\n",
      "8 10.5 12.5 0.736731196214\n",
      "9 10.5 12.5 0.73837702971\n",
      "10 10.5 12.5 0.739981065581\n",
      "11 10.5 12.5 0.738863826522\n",
      "12 10.5 12.5 0.740111174796\n",
      "13 10.5 12.5 0.739939945276\n",
      "14 10.5 12.5 0.741443207133\n",
      "15 10.5 12.5 0.740993856877\n",
      "3 10.5 13.0 0.716063557883\n",
      "4 10.5 13.0 0.724995538778\n",
      "5 10.5 13.0 0.72814531547\n",
      "6 10.5 13.0 0.732655327388\n",
      "7 10.5 13.0 0.733657556998\n",
      "8 10.5 13.0 0.736731196214\n",
      "9 10.5 13.0 0.73837702971\n",
      "10 10.5 13.0 0.739981065581\n",
      "11 10.5 13.0 0.738863826522\n",
      "12 10.5 13.0 0.740111174796\n",
      "13 10.5 13.0 0.739939945276\n",
      "14 10.5 13.0 0.741443207133\n",
      "15 10.5 13.0 0.740993856877\n",
      "3 10.5 13.5 0.716063557883\n",
      "4 10.5 13.5 0.724995538778\n",
      "5 10.5 13.5 0.72814531547\n",
      "6 10.5 13.5 0.732655327388\n",
      "7 10.5 13.5 0.733657556998\n",
      "8 10.5 13.5 0.736731196214\n",
      "9 10.5 13.5 0.73837702971\n",
      "10 10.5 13.5 0.739981065581\n",
      "11 10.5 13.5 0.738863826522\n",
      "12 10.5 13.5 0.740111174796\n",
      "13 10.5 13.5 0.739939945276\n",
      "14 10.5 13.5 0.741443207133\n",
      "15 10.5 13.5 0.740993856877\n",
      "3 10.5 14.0 0.716063557883\n",
      "4 10.5 14.0 0.724995538778\n",
      "5 10.5 14.0 0.72814531547\n",
      "6 10.5 14.0 0.732655327388\n",
      "7 10.5 14.0 0.733657556998\n",
      "8 10.5 14.0 0.736731196214\n",
      "9 10.5 14.0 0.73837702971\n",
      "10 10.5 14.0 0.739981065581\n",
      "11 10.5 14.0 0.738863826522\n",
      "12 10.5 14.0 0.740111174796\n",
      "13 10.5 14.0 0.739939945276\n",
      "14 10.5 14.0 0.741443207133\n",
      "15 10.5 14.0 0.740993856877\n",
      "3 10.5 14.5 0.716063557883\n",
      "4 10.5 14.5 0.724995538778\n",
      "5 10.5 14.5 0.72814531547\n",
      "6 10.5 14.5 0.732655327388\n",
      "7 10.5 14.5 0.733657556998\n",
      "8 10.5 14.5 0.736731196214\n",
      "9 10.5 14.5 0.73837702971\n",
      "10 10.5 14.5 0.739981065581\n",
      "11 10.5 14.5 0.738863826522\n",
      "12 10.5 14.5 0.740111174796\n",
      "13 10.5 14.5 0.739939945276\n",
      "14 10.5 14.5 0.741443207133\n",
      "15 10.5 14.5 0.740993856877\n",
      "3 10.5 15.0 0.716063557883\n",
      "4 10.5 15.0 0.724995538778\n",
      "5 10.5 15.0 0.72814531547\n",
      "6 10.5 15.0 0.732655327388\n",
      "7 10.5 15.0 0.733657556998\n",
      "8 10.5 15.0 0.736731196214\n",
      "9 10.5 15.0 0.73837702971\n",
      "10 10.5 15.0 0.739981065581\n",
      "11 10.5 15.0 0.738863826522\n",
      "12 10.5 15.0 0.740111174796\n",
      "13 10.5 15.0 0.739939945276\n",
      "14 10.5 15.0 0.741443207133\n",
      "15 10.5 15.0 0.740993856877\n",
      "3 10.5 15.5 0.716063557883\n",
      "4 10.5 15.5 0.724995538778\n",
      "5 10.5 15.5 0.72814531547\n",
      "6 10.5 15.5 0.732655327388\n",
      "7 10.5 15.5 0.733657556998\n",
      "8 10.5 15.5 0.736731196214\n",
      "9 10.5 15.5 0.73837702971\n",
      "10 10.5 15.5 0.739981065581\n",
      "11 10.5 15.5 0.738863826522\n",
      "12 10.5 15.5 0.740111174796\n",
      "13 10.5 15.5 0.739939945276\n",
      "14 10.5 15.5 0.741443207133\n",
      "15 10.5 15.5 0.740993856877\n",
      "3 10.5 16.0 0.716063557883\n",
      "4 10.5 16.0 0.724995538778\n",
      "5 10.5 16.0 0.72814531547\n",
      "6 10.5 16.0 0.732655327388\n",
      "7 10.5 16.0 0.733657556998\n",
      "8 10.5 16.0 0.736731196214\n",
      "9 10.5 16.0 0.73837702971\n",
      "10 10.5 16.0 0.739981065581\n",
      "11 10.5 16.0 0.738863826522\n",
      "12 10.5 16.0 0.740111174796\n",
      "13 10.5 16.0 0.739939945276\n",
      "14 10.5 16.0 0.741443207133\n",
      "15 10.5 16.0 0.740993856877\n",
      "3 10.5 16.5 0.716063557883\n",
      "4 10.5 16.5 0.724995538778\n",
      "5 10.5 16.5 0.72814531547\n",
      "6 10.5 16.5 0.732655327388\n",
      "7 10.5 16.5 0.733657556998\n",
      "8 10.5 16.5 0.736731196214\n",
      "9 10.5 16.5 0.73837702971\n",
      "10 10.5 16.5 0.739981065581\n",
      "11 10.5 16.5 0.738863826522\n",
      "12 10.5 16.5 0.740111174796\n",
      "13 10.5 16.5 0.739939945276\n",
      "14 10.5 16.5 0.741443207133\n",
      "15 10.5 16.5 0.740993856877\n",
      "3 10.5 17.0 0.716063557883\n",
      "4 10.5 17.0 0.724995538778\n",
      "5 10.5 17.0 0.72814531547\n",
      "6 10.5 17.0 0.732655327388\n",
      "7 10.5 17.0 0.733657556998\n",
      "8 10.5 17.0 0.736731196214\n",
      "9 10.5 17.0 0.73837702971\n",
      "10 10.5 17.0 0.739981065581\n",
      "11 10.5 17.0 0.738863826522\n",
      "12 10.5 17.0 0.740111174796\n",
      "13 10.5 17.0 0.739939945276\n",
      "14 10.5 17.0 0.741443207133\n",
      "15 10.5 17.0 0.740993856877\n",
      "3 10.5 17.5 0.716063557883\n",
      "4 10.5 17.5 0.724995538778\n",
      "5 10.5 17.5 0.72814531547\n",
      "6 10.5 17.5 0.732655327388\n",
      "7 10.5 17.5 0.733657556998\n",
      "8 10.5 17.5 0.736731196214\n",
      "9 10.5 17.5 0.73837702971\n",
      "10 10.5 17.5 0.739981065581\n",
      "11 10.5 17.5 0.738863826522\n",
      "12 10.5 17.5 0.740111174796\n",
      "13 10.5 17.5 0.739939945276\n",
      "14 10.5 17.5 0.741443207133\n",
      "15 10.5 17.5 0.740993856877\n",
      "12 4 0 0.741443207133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "k=0\n",
    "i=0.5\n",
    "j=0.5\n",
    "ans=0\n",
    "lugg=0\n",
    "wait=0\n",
    "neighbo=0\n",
    "for i in frange(4,11,0.5):\n",
    "    for j in frange(12,18,0.5):\n",
    "        iris=pd.read_csv('intracity_fare_train.csv')\n",
    "        data = pd.DataFrame(iris)\n",
    "        iris.drop_duplicates(subset=[ 'STARTING_LATITUDE', 'STARTING_LONGITUDE', 'DESTINATION_LATITUDE','DESTINATION_LONGITUDE','VEHICLE_TYPE','TOTAL_LUGGAGE_WEIGHT','WAIT_TIME','TRAFFIC_STUCK_TIME', 'DISTANCE','FARE'],inplace=True)\n",
    "        df= pd.DataFrame(iris)\n",
    "        df['VEHICLE_TYPE']=df['VEHICLE_TYPE'].apply(lambda x: x.upper())\n",
    "        df['TOTAL_LUGGAGE_WEIGHT']=df['TOTAL_LUGGAGE_WEIGHT'].fillna(i)\n",
    "        target_map = {'AC BUS':3,'AUTO RICKSHAW':4,'BUS':1,'METRO':2,'MINI BUS':0, 'TAXI AC':6, 'TAXI NON AC':5}\n",
    "        df['VEHICLE_TYPE']=df['VEHICLE_TYPE'].apply(lambda x: target_map[x])\n",
    "        df=df.dropna()\n",
    "        df['WAIT_TIME']=df['WAIT_TIME'].fillna(j)\n",
    "        train, test = train_test_split(df, test_size = 0.3, random_state=1212)# in this our main data is split into train and test\n",
    "        train_X = train[['STARTING_LATITUDE', 'STARTING_LONGITUDE', 'DESTINATION_LATITUDE', 'DESTINATION_LONGITUDE', 'VEHICLE_TYPE', 'TOTAL_LUGGAGE_WEIGHT', 'WAIT_TIME','DISTANCE']]# taking the training data features\n",
    "\n",
    "        train_y = train[['FARE']]# output of our training data\n",
    "        test_X = test[[\n",
    "             'STARTING_LATITUDE',\n",
    "             'STARTING_LONGITUDE',\n",
    "             'DESTINATION_LATITUDE',\n",
    "             'DESTINATION_LONGITUDE',\n",
    "             'VEHICLE_TYPE',\n",
    "             'TOTAL_LUGGAGE_WEIGHT',\n",
    "             'WAIT_TIME',\n",
    "\n",
    "             'DISTANCE']]# taking the training data features\n",
    "            # taking test data features\n",
    "        test_y = test[['FARE']]   #output value of test data\n",
    "        for k in range(3,16):\n",
    "            neigh = KNeighborsRegressor(n_neighbors=k,algorithm='auto',weights='distance')\n",
    "\n",
    "            prediction=neigh.fit(train_X, train_y).predict(test_X)\n",
    "            a=r2_score(prediction,test_y)\n",
    "            if a>ans :\n",
    "                ans=a\n",
    "                wait=j\n",
    "                lugg=i\n",
    "                neigbo=k\n",
    "        \n",
    "            print(k,i,j,a)\n",
    "print(wait,lugg,neighbo,ans)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
